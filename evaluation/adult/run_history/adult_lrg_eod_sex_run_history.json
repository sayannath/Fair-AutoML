[
    {
        "config_id": 1,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01,
            "feature_preprocessor:kitchen_sinks:gamma": 1.0,
            "feature_preprocessor:kitchen_sinks:n_components": 100
        },
        "cost": 0.0,
        "time": 0.12279605865478516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Default"
        }
    },
    {
        "config_id": 2,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003204801635384316,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0966057427973706,
        "time": 3.509561061859131,
        "additional_info": {
            "duration": 3.500379800796509,
            "num_run": 3,
            "train_loss": 1.0786012328982921,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 3,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12251030897089438,
            "feature_preprocessor:select_percentile_classification:percentile": 6.890541497801536,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0839849075122532,
        "time": 2.328099012374878,
        "additional_info": {
            "duration": 2.3191659450531006,
            "num_run": 4,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 4,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1306750213808685,
        "time": 4.36880087852478,
        "additional_info": {
            "duration": 4.359558820724487,
            "num_run": 5,
            "train_loss": 1.0712476710468886,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 5,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0948139957818912,
        "time": 3.2292799949645996,
        "additional_info": {
            "duration": 3.220374822616577,
            "num_run": 6,
            "train_loss": 1.08157593327207,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 6,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08027808269440723,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2664356104076306,
        "time": 2.934844970703125,
        "additional_info": {
            "duration": 2.926408290863037,
            "num_run": 7,
            "train_loss": 1.0697605069287017,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 7,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10302819201326878,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.126052066092325,
        "time": 4.393197059631348,
        "additional_info": {
            "duration": 4.384169816970825,
            "num_run": 8,
            "train_loss": 1.0711197056755613,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 8,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1711,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.158919095993042,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 9,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 4.4057453667032355e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 748
        },
        "cost": 0.0,
        "time": 0.14258313179016113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 10,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 2.883736828549079,
            "feature_preprocessor:kitchen_sinks:n_components": 146
        },
        "cost": 0.0,
        "time": 0.15948915481567383,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 11,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0682298837693858,
        "time": 22.661620140075684,
        "additional_info": {
            "duration": 22.6523699760437,
            "num_run": 12,
            "train_loss": 1.0742073028650614,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 12,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1046845842193838,
        "time": 4.056246042251587,
        "additional_info": {
            "duration": 4.047650098800659,
            "num_run": 13,
            "train_loss": 1.0605986323327332,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 13,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7356999096162236,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1729482464216646,
            "feature_preprocessor:kitchen_sinks:gamma": 1.2510172908492618,
            "feature_preprocessor:kitchen_sinks:n_components": 1165
        },
        "cost": 0.0,
        "time": 0.16045165061950684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 14,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.101441097886764,
        "time": 21.767579078674316,
        "additional_info": {
            "duration": 21.75913095474243,
            "num_run": 15,
            "train_loss": 1.0644568614146548,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 15,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005135191019114122,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0002139583607170795,
            "feature_preprocessor:kitchen_sinks:n_components": 704
        },
        "cost": 0.0,
        "time": 0.13192510604858398,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 16,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000821201772374995,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.750719014532631,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2127388366803427,
            "feature_preprocessor:kitchen_sinks:gamma": 0.14052360477264206,
            "feature_preprocessor:kitchen_sinks:n_components": 897
        },
        "cost": 0.0,
        "time": 0.21190929412841797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 17,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006464622287274047,
            "feature_preprocessor:kitchen_sinks:n_components": 335
        },
        "cost": 0.0,
        "time": 0.11612105369567871,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 18,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.300660213340011e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 62
        },
        "cost": 0.0,
        "time": 0.17107510566711426,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 19,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05347677271044051,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1141798538177723,
        "time": 4.0369768142700195,
        "additional_info": {
            "duration": 4.028578758239746,
            "num_run": 20,
            "train_loss": 1.0645897675782199,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 20,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000173548247382744,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0007748565338634348,
            "feature_preprocessor:kitchen_sinks:n_components": 265
        },
        "cost": 0.0,
        "time": 0.1600329875946045,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 21,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010664300128633615,
            "feature_preprocessor:kitchen_sinks:gamma": 1.0311337872425532,
            "feature_preprocessor:kitchen_sinks:n_components": 145
        },
        "cost": 0.0,
        "time": 0.14512300491333008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 22,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010341322261869662,
            "feature_preprocessor:kitchen_sinks:gamma": 0.013587145918956708,
            "feature_preprocessor:kitchen_sinks:n_components": 1507
        },
        "cost": 0.0,
        "time": 0.441727876663208,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 23,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00212804926182438,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 269,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 2.9409340980938343,
            "feature_preprocessor:kitchen_sinks:n_components": 923
        },
        "cost": 0.0,
        "time": 0.278731107711792,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 24,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0997016584963635,
        "time": 4.100383996963501,
        "additional_info": {
            "duration": 4.092045068740845,
            "num_run": 25,
            "train_loss": 1.0712427302546508,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 25,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.028364474859015613,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7462672949954833,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.013532764044479152,
            "feature_preprocessor:select_percentile_classification:percentile": 77.22135268328647,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2103271399658984,
        "time": 2.507849931716919,
        "additional_info": {
            "duration": 2.498936891555786,
            "num_run": 26,
            "train_loss": 1.0773126851851773,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 26,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03033005191484316,
            "feature_preprocessor:select_percentile_classification:percentile": 35.70742454406841,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0899467260508833,
        "time": 2.7449610233306885,
        "additional_info": {
            "duration": 2.736093282699585,
            "num_run": 27,
            "train_loss": 1.066269745683119,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 27,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 39.279816139327025,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.102437065250987,
        "time": 2.4039900302886963,
        "additional_info": {
            "duration": 2.3955700397491455,
            "num_run": 28,
            "train_loss": 1.0800370139248343,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 28,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003400756633119951,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2155644757973176,
        "time": 13.31095290184021,
        "additional_info": {
            "duration": 13.302304029464722,
            "num_run": 29,
            "train_loss": 1.0751940929833446,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 29,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 904,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.004798701214395358,
            "feature_preprocessor:kitchen_sinks:n_components": 7861
        },
        "cost": 0.0,
        "time": 0.25861668586730957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 30,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013680235727547407,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.3552992140281706,
        "time": 10.226331949234009,
        "additional_info": {
            "duration": 10.216985940933228,
            "num_run": 31,
            "train_loss": 1.068611165893428,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 31,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007493858943372333,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1400723330695037,
        "time": 21.852813720703125,
        "additional_info": {
            "duration": 21.84446120262146,
            "num_run": 32,
            "train_loss": 1.064720203345666,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 32,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006138567315860528,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.090292925064281,
        "time": 10.119432926177979,
        "additional_info": {
            "duration": 10.111300230026245,
            "num_run": 33,
            "train_loss": 1.086444668848828,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 33,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10196569591800218,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7317459876621641,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0915859874589704,
            "feature_preprocessor:kitchen_sinks:gamma": 4.2202686460575503e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 601
        },
        "cost": 0.0,
        "time": 0.15074896812438965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 34,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1541,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.01473760595350275,
            "feature_preprocessor:kitchen_sinks:n_components": 70
        },
        "cost": 0.0,
        "time": 0.27027130126953125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 35,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 280,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.009396242536775378,
            "feature_preprocessor:kitchen_sinks:n_components": 892
        },
        "cost": 0.0,
        "time": 0.20607471466064453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 36,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0260008157701054,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0945445476429263,
        "time": 3.871002197265625,
        "additional_info": {
            "duration": 3.8613109588623047,
            "num_run": 37,
            "train_loss": 1.081099644917058,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 37,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09846210710801165,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 382,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1145599287033494,
        "time": 22.812851905822754,
        "additional_info": {
            "duration": 22.80351996421814,
            "num_run": 38,
            "train_loss": 1.0665060363462693,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 38,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0980064894161454,
        "time": 3.3367931842803955,
        "additional_info": {
            "duration": 3.327655792236328,
            "num_run": 39,
            "train_loss": 1.0806008768180846,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 39,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8578789019352311,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2667824444904926,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1863229066895142,
        "time": 4.025738954544067,
        "additional_info": {
            "duration": 4.016981840133667,
            "num_run": 40,
            "train_loss": 1.162926568139545,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 40,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8719554568390984,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07052211395270751,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0839849075122532,
        "time": 10.020814895629883,
        "additional_info": {
            "duration": 10.011894941329956,
            "num_run": 41,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 41,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1212,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.029576790428712543,
            "feature_preprocessor:kitchen_sinks:n_components": 2238
        },
        "cost": 0.0,
        "time": 0.2541229724884033,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 42,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.6251430174027156,
            "feature_preprocessor:kitchen_sinks:n_components": 103
        },
        "cost": 0.0,
        "time": 0.11774373054504395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 43,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011426691346968176,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1780,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1251081865826258,
        "time": 4.983554124832153,
        "additional_info": {
            "duration": 4.972936153411865,
            "num_run": 44,
            "train_loss": 1.0741893917759335,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 44,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006340589161613562,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8905881516718835,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19896477898539458,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.092464092287504,
        "time": 4.435431003570557,
        "additional_info": {
            "duration": 4.426780700683594,
            "num_run": 45,
            "train_loss": 1.0706066104267253,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 45,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04604042035741955,
            "feature_preprocessor:kitchen_sinks:gamma": 1.112427916156596,
            "feature_preprocessor:kitchen_sinks:n_components": 5288
        },
        "cost": 0.0,
        "time": 0.14281511306762695,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 46,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00016913542967645514,
            "feature_preprocessor:kitchen_sinks:n_components": 799
        },
        "cost": 0.0,
        "time": 0.11502385139465332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 47,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012836986675553073,
            "feature_preprocessor:select_percentile_classification:percentile": 11.284905962262853,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0954633952104302,
        "time": 2.3332579135894775,
        "additional_info": {
            "duration": 2.3247690200805664,
            "num_run": 48,
            "train_loss": 1.08157593327207,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 48,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002825027944772885,
            "feature_preprocessor:kitchen_sinks:gamma": 0.05200007540228999,
            "feature_preprocessor:kitchen_sinks:n_components": 51
        },
        "cost": 0.0,
        "time": 0.14510011672973633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 49,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1605,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.15178742386307223,
            "feature_preprocessor:kitchen_sinks:n_components": 2129
        },
        "cost": 0.0,
        "time": 0.24207210540771484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 50,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006101999220662837,
            "feature_preprocessor:kitchen_sinks:gamma": 0.03381367853249621,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.17499184608459473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 51,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00041981893273946273,
            "feature_preprocessor:kitchen_sinks:gamma": 0.10703207031204037,
            "feature_preprocessor:kitchen_sinks:n_components": 324
        },
        "cost": 0.0,
        "time": 0.1469879150390625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 52,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05099360711103528,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1140843078479064,
        "time": 4.104541778564453,
        "additional_info": {
            "duration": 4.0953216552734375,
            "num_run": 53,
            "train_loss": 1.0649167214920234,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 53,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009962759873930532,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1378,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.123904024397513,
        "time": 4.714542865753174,
        "additional_info": {
            "duration": 4.703739166259766,
            "num_run": 54,
            "train_loss": 1.0729889138279074,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 54,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006848724048549714,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 768,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 73.48624063344404,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0839849075122532,
        "time": 4.424126863479614,
        "additional_info": {
            "duration": 4.414259910583496,
            "num_run": 55,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 55,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.027760752222854478,
            "feature_preprocessor:select_percentile_classification:percentile": 63.021259101925885,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.149282783354095,
        "time": 2.4645581245422363,
        "additional_info": {
            "duration": 2.455219030380249,
            "num_run": 56,
            "train_loss": 1.0734743423616524,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 56,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.005315892809890848,
            "feature_preprocessor:kitchen_sinks:n_components": 1913
        },
        "cost": 0.0,
        "time": 0.14804577827453613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 57,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010193470235548893,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 496,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.114050350197397,
        "time": 23.054367065429688,
        "additional_info": {
            "duration": 23.045634031295776,
            "num_run": 58,
            "train_loss": 1.060409525374732,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 58,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.004689996567878386,
            "feature_preprocessor:kitchen_sinks:n_components": 6348
        },
        "cost": 0.0,
        "time": 0.1732349395751953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 59,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3556795751100918,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1325,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2781052589416504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 60,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 72,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.8535032376908613,
            "feature_preprocessor:kitchen_sinks:n_components": 51
        },
        "cost": 0.0,
        "time": 0.25985002517700195,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 61,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10002968401828828,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1438,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1364144726912553,
        "time": 4.290189743041992,
        "additional_info": {
            "duration": 4.280210256576538,
            "num_run": 62,
            "train_loss": 1.0698721671118316,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 62,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1181617452961348,
        "time": 12.784420728683472,
        "additional_info": {
            "duration": 12.776154279708862,
            "num_run": 63,
            "train_loss": 1.0714961906011868,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 63,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1890,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1302989874586908,
        "time": 22.140519857406616,
        "additional_info": {
            "duration": 22.130659103393555,
            "num_run": 64,
            "train_loss": 1.0569196286243376,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 64,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07786498185598252,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1676,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 23.093135112117103,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1626930513328324,
        "time": 2.914975881576538,
        "additional_info": {
            "duration": 2.9060862064361572,
            "num_run": 65,
            "train_loss": 1.0646795663336848,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 65,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1237853180497244,
        "time": 4.471830129623413,
        "additional_info": {
            "duration": 4.4629271030426025,
            "num_run": 66,
            "train_loss": 1.0699819752151394,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 66,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.137284236759701,
        "time": 24.335926055908203,
        "additional_info": {
            "duration": 24.326546907424927,
            "num_run": 67,
            "train_loss": 1.065908329313098,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 67,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1503,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2018816884193564,
        "time": 13.749523878097534,
        "additional_info": {
            "duration": 13.740508079528809,
            "num_run": 68,
            "train_loss": 1.0593352838076568,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 68,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10002968401828828,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1438,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 50.0,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.145253561924697,
        "time": 2.593568801879883,
        "additional_info": {
            "duration": 2.583937883377075,
            "num_run": 69,
            "train_loss": 1.069137231439154,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 69,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08819562507684088,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 631,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2475087429683696,
        "time": 11.43467116355896,
        "additional_info": {
            "duration": 11.425549268722534,
            "num_run": 70,
            "train_loss": 1.0546844354471372,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 70,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1559,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1168311344889612,
        "time": 22.328611850738525,
        "additional_info": {
            "duration": 22.319926023483276,
            "num_run": 71,
            "train_loss": 1.058525494845673,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 71,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3678797302672401,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1569,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.126662557609055,
        "time": 21.598901987075806,
        "additional_info": {
            "duration": 21.58951997756958,
            "num_run": 72,
            "train_loss": 1.0536344026143996,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 72,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10196569591800218,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 922,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.332423164279236,
        "time": 9.255957126617432,
        "additional_info": {
            "duration": 9.246870994567871,
            "num_run": 73,
            "train_loss": 1.074747326292312,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 73,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10197732707004778,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1659,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2475405916249915,
        "time": 11.627058744430542,
        "additional_info": {
            "duration": 11.61706805229187,
            "num_run": 74,
            "train_loss": 1.0547001223190382,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 74,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.060139364322877e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 61
        },
        "cost": 0.0,
        "time": 0.14913201332092285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 75,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1918,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.13081551692339116,
            "feature_preprocessor:kitchen_sinks:n_components": 3056
        },
        "cost": 0.0,
        "time": 0.3116729259490967,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 76,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005849820332193602,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.125642857436013,
        "time": 20.20079517364502,
        "additional_info": {
            "duration": 20.190540075302124,
            "num_run": 77,
            "train_loss": 1.0482232963037181,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 77,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14791630494256483,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1695,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.123528836582473,
        "time": 4.764750003814697,
        "additional_info": {
            "duration": 4.754484176635742,
            "num_run": 78,
            "train_loss": 1.0704938367004486,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 78,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014034647564870608,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1731,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.213789224624634,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 79,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008585160766540348,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9851203952456908,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18593899259331634,
            "feature_preprocessor:select_percentile_classification:percentile": 96.0848641479175,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1484288300102987,
        "time": 2.6123199462890625,
        "additional_info": {
            "duration": 2.603670120239258,
            "num_run": 80,
            "train_loss": 1.066864240914429,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 80,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020600825884815872,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1700,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.239867925643921,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 81,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004654572535916448,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1700,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 46.42216204945104,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0839849075122532,
        "time": 2.6269822120666504,
        "additional_info": {
            "duration": 2.6162240505218506,
            "num_run": 82,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 82,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0911276135558543,
        "time": 4.347135782241821,
        "additional_info": {
            "duration": 4.338229179382324,
            "num_run": 83,
            "train_loss": 1.0651304093217666,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 83,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8358318340237377,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03477892232418243,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1839482495717115,
        "time": 4.049466133117676,
        "additional_info": {
            "duration": 4.040639162063599,
            "num_run": 84,
            "train_loss": 1.1629397846153273,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 84,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017493979749629931,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1698,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2475087429683696,
        "time": 11.358057975769043,
        "additional_info": {
            "duration": 11.348401069641113,
            "num_run": 85,
            "train_loss": 1.0546844354471372,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 85,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003000868230625274,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1708,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2665001914630472,
        "time": 3.0949978828430176,
        "additional_info": {
            "duration": 3.0858919620513916,
            "num_run": 86,
            "train_loss": 1.0685980725070918,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 86,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.060139364322877e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 61
        },
        "cost": 0.0,
        "time": 0.14762187004089355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 87,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1303980818736679,
        "time": 4.390123128890991,
        "additional_info": {
            "duration": 4.381799936294556,
            "num_run": 88,
            "train_loss": 1.0666579642730425,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 88,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00800799710265374,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1698,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1804349422454834,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 89,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1697,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.184748649597168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 90,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1697,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1975419521331787,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 91,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00038536686281994315,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0676636672053765,
        "time": 23.366554260253906,
        "additional_info": {
            "duration": 23.357025861740112,
            "num_run": 92,
            "train_loss": 1.0733362492269578,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 92,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4774768522791864,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 454,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 9.982438066532609,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.180488584514264,
        "time": 2.6967077255249023,
        "additional_info": {
            "duration": 2.6878890991210938,
            "num_run": 93,
            "train_loss": 1.0803765659981241,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 93,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1825,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.324454722856412,
        "time": 10.365813970565796,
        "additional_info": {
            "duration": 10.356132984161377,
            "num_run": 94,
            "train_loss": 1.0788260360760367,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 94,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1697,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 50.0,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0839849075122532,
        "time": 2.6111340522766113,
        "additional_info": {
            "duration": 2.6011910438537598,
            "num_run": 95,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 95,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 5.036049758772094,
            "feature_preprocessor:kitchen_sinks:n_components": 211
        },
        "cost": 0.0,
        "time": 0.4732067584991455,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 96,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9692212744557289,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2352299459340834,
            "feature_preprocessor:kitchen_sinks:gamma": 0.09496163430036579,
            "feature_preprocessor:kitchen_sinks:n_components": 60
        },
        "cost": 0.0,
        "time": 0.15021204948425293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 97,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2217617137080431,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1356,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.002250223723398456,
            "feature_preprocessor:kitchen_sinks:n_components": 3096
        },
        "cost": 0.0,
        "time": 0.2722618579864502,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 98,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1723,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.144110679626465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 99,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 559,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 63.295311981463236,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1416543477725951,
        "time": 2.5917139053344727,
        "additional_info": {
            "duration": 2.582386016845703,
            "num_run": 100,
            "train_loss": 1.067244060731362,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 100,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1886,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.332423164279236,
        "time": 9.38483715057373,
        "additional_info": {
            "duration": 9.375745058059692,
            "num_run": 101,
            "train_loss": 1.074747326292312,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 101,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018289683900224053,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1694,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.299384832382202,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 102,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1720,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1194926190886507,
        "time": 4.754581928253174,
        "additional_info": {
            "duration": 4.744286775588989,
            "num_run": 103,
            "train_loss": 1.0720080520864963,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 103,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020222113913682003,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1691,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2250401973724365,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 104,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0033597835314524782,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1064,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.0956499576568604,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 105,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04970436650641324,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1694,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1181292136204277,
        "time": 4.7881951332092285,
        "additional_info": {
            "duration": 4.779012203216553,
            "num_run": 106,
            "train_loss": 1.0733001808698102,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 106,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.057998418182905125,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1656,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 3.270787011849496,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0839849075122532,
        "time": 4.294281959533691,
        "additional_info": {
            "duration": 4.285102844238281,
            "num_run": 107,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 107,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7580690026315976,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23049277300214202,
            "feature_preprocessor:select_percentile_classification:percentile": 6.033900059849137,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.209761200792161,
        "time": 2.3280868530273438,
        "additional_info": {
            "duration": 2.3192813396453857,
            "num_run": 108,
            "train_loss": 1.0670127108604492,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 108,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.028603628349309768,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1690,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.324454722856412,
        "time": 10.314971208572388,
        "additional_info": {
            "duration": 10.305383205413818,
            "num_run": 109,
            "train_loss": 1.0788260360760367,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 109,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1573,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1542298793792725,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 110,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026047679017597376,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1099,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.118629217147827,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 111,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.47868236215014276,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1648,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.13029408454895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 112,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 76.7911399163202,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0832407742999814,
        "time": 4.300778150558472,
        "additional_info": {
            "duration": 4.292032957077026,
            "num_run": 113,
            "train_loss": 1.0784113845345487,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 113,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006763417852994758,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1691,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1558949947357178,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 114,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001054267006674535,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1279490309958322,
        "time": 4.269618988037109,
        "additional_info": {
            "duration": 4.2609429359436035,
            "num_run": 115,
            "train_loss": 1.0607809464186744,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 115,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0888537202331432,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1478,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 97.37986990174781,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.133751637386833,
        "time": 4.913267135620117,
        "additional_info": {
            "duration": 4.904539108276367,
            "num_run": 116,
            "train_loss": 1.0681464881132678,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 116,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04681544472217236,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0032289514519654957,
            "feature_preprocessor:kitchen_sinks:n_components": 134
        },
        "cost": 0.0,
        "time": 0.16498208045959473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 117,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1450,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.282351016998291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 118,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 841,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2268447875976562,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 119,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 13.331990940941825,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1186792036086834,
        "time": 2.3104913234710693,
        "additional_info": {
            "duration": 2.301680088043213,
            "num_run": 120,
            "train_loss": 1.063189313503083,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 120,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 29.74118613232918,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.095204365199475,
        "time": 4.207346200942993,
        "additional_info": {
            "duration": 4.198406934738159,
            "num_run": 121,
            "train_loss": 1.0788530873438975,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 121,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030893108677623516,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9382532307430916,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2591797934604746,
            "feature_preprocessor:kitchen_sinks:gamma": 0.006658533904246124,
            "feature_preprocessor:kitchen_sinks:n_components": 453
        },
        "cost": 0.0,
        "time": 0.18638896942138672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 122,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002042788337391132,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 602,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.123879891530927,
        "time": 20.431337118148804,
        "additional_info": {
            "duration": 20.421043872833252,
            "num_run": 123,
            "train_loss": 1.057244853547765,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 123,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4343057126382794,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.097606516842209,
        "time": 3.791342258453369,
        "additional_info": {
            "duration": 3.7827959060668945,
            "num_run": 124,
            "train_loss": 1.0717893003750696,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 124,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0676636672053765,
        "time": 22.4152250289917,
        "additional_info": {
            "duration": 22.405567169189453,
            "num_run": 125,
            "train_loss": 1.0733362492269578,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 125,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.021732088987185098,
            "feature_preprocessor:kitchen_sinks:n_components": 8099
        },
        "cost": 0.0,
        "time": 0.14862704277038574,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 126,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0032792627711670406,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.135483045033383,
        "time": 25.641722202301025,
        "additional_info": {
            "duration": 25.63196325302124,
            "num_run": 127,
            "train_loss": 1.0648308759441618,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 127,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1063,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.19488787651062,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 128,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012367855167735448,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1243564216842705,
        "time": 19.387446880340576,
        "additional_info": {
            "duration": 19.37892985343933,
            "num_run": 129,
            "train_loss": 1.0487384926803347,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 129,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 774,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.196406126022339,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 130,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022478127964466998,
            "feature_preprocessor:kitchen_sinks:gamma": 0.09933166126005735,
            "feature_preprocessor:kitchen_sinks:n_components": 284
        },
        "cost": 0.0,
        "time": 0.16582798957824707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 131,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015253635530309829,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1077,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.239651918411255,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 132,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011302231903714509,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 552,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.3098630905151367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 133,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011742935140808845,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1587,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.19885516166687,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 134,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 93.65229893760382,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2039654018218033,
        "time": 2.3887388706207275,
        "additional_info": {
            "duration": 2.3785829544067383,
            "num_run": 135,
            "train_loss": 1.0701378563495156,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 135,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1367552094036051,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1972148418426514,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 136,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 51.64876000246462,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.093948341438654,
        "time": 4.19939112663269,
        "additional_info": {
            "duration": 4.190553903579712,
            "num_run": 137,
            "train_loss": 1.063059742230825,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 137,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0848583636284682,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9570700810035175,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04904469816679123,
            "feature_preprocessor:select_percentile_classification:percentile": 92.03665478187693,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2712606811873086,
        "time": 4.343591928482056,
        "additional_info": {
            "duration": 4.333883047103882,
            "num_run": 138,
            "train_loss": 1.0711014253180953,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 138,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009847385297399206,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 515,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.0884628295898438,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 139,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006749138308284435,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 498,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.160975217819214,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 140,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11989572325145528,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1553,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1576746773966229,
        "time": 3.416165828704834,
        "additional_info": {
            "duration": 3.406759262084961,
            "num_run": 141,
            "train_loss": 1.0630102112190032,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 141,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1281,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.130735043867476,
        "time": 20.302872896194458,
        "additional_info": {
            "duration": 20.29238986968994,
            "num_run": 142,
            "train_loss": 1.057591693719965,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 142,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016941623918917737,
            "feature_preprocessor:kitchen_sinks:gamma": 0.48993607354631236,
            "feature_preprocessor:kitchen_sinks:n_components": 129
        },
        "cost": 0.0,
        "time": 0.4717881679534912,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 143,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024270613511575605,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 438,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1976237297058105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 144,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8551827993918146,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15330928042058006,
            "feature_preprocessor:kitchen_sinks:gamma": 0.14975389523011884,
            "feature_preprocessor:kitchen_sinks:n_components": 1059
        },
        "cost": 0.0,
        "time": 0.15109515190124512,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 145,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 535,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.168862819671631,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 146,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020494095678056712,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1236,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1291322305434004,
        "time": 4.1968159675598145,
        "additional_info": {
            "duration": 4.187038898468018,
            "num_run": 147,
            "train_loss": 1.073234962986087,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 147,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1782,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2395191192626953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 148,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019126794679698442,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1698,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.157142162322998,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 149,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000363421267888767,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1900,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 6.324196193160627,
            "feature_preprocessor:kitchen_sinks:n_components": 109
        },
        "cost": 0.0,
        "time": 0.2482011318206787,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 150,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.3324550129358577,
        "time": 9.135385990142822,
        "additional_info": {
            "duration": 9.12574315071106,
            "num_run": 151,
            "train_loss": 1.074747326292312,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 151,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0021409861809671017,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2336909770965576,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 152,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1945,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.247793197631836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 153,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.002548503759857269,
            "feature_preprocessor:kitchen_sinks:n_components": 91
        },
        "cost": 0.0,
        "time": 0.14838600158691406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 154,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.088207426063562,
            "feature_preprocessor:kitchen_sinks:gamma": 0.028736430485236976,
            "feature_preprocessor:kitchen_sinks:n_components": 110
        },
        "cost": 0.0,
        "time": 0.1457211971282959,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 155,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017851055686855195,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 305,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2432501316070557,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 156,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9036492984768192,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15842221817768842,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0818188489871379,
        "time": 4.515294075012207,
        "additional_info": {
            "duration": 4.506282091140747,
            "num_run": 157,
            "train_loss": 1.0707899120973006,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 157,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 908,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.21856689453125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 158,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005035039583449875,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1723,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.254958152770996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 159,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1756,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.322618007659912,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 160,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00245777576354578,
            "feature_preprocessor:kitchen_sinks:gamma": 0.01635836680705326,
            "feature_preprocessor:kitchen_sinks:n_components": 7356
        },
        "cost": 0.0,
        "time": 0.14534306526184082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 161,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004743890335344976,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00012970081742675626,
            "feature_preprocessor:kitchen_sinks:n_components": 94
        },
        "cost": 0.0,
        "time": 0.1730806827545166,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 162,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.41322721238762034,
            "feature_preprocessor:select_percentile_classification:percentile": 2.884671554929607,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.072924682417243,
        "time": 4.2100749015808105,
        "additional_info": {
            "duration": 4.2012951374053955,
            "num_run": 163,
            "train_loss": 1.0732139660536102,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 163,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1153282872427286,
        "time": 4.290673732757568,
        "additional_info": {
            "duration": 4.28148889541626,
            "num_run": 164,
            "train_loss": 1.0679418173728117,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 164,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.26790134022380657,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1327,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.207988977432251,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 165,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0050167256761224485,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1661,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 57.181645346904574,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0839849075122532,
        "time": 2.593273162841797,
        "additional_info": {
            "duration": 2.5837628841400146,
            "num_run": 166,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 166,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 74.87766475428384,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1459719625166294,
        "time": 2.7906076908111572,
        "additional_info": {
            "duration": 2.781747817993164,
            "num_run": 167,
            "train_loss": 1.075226331222335,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 167,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017967426159628166,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 227,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.204582929611206,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 168,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8096839946464501,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17692439511092264,
            "feature_preprocessor:select_percentile_classification:percentile": 51.52541434878627,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.166117842456296,
        "time": 2.4530110359191895,
        "additional_info": {
            "duration": 2.444059133529663,
            "num_run": 169,
            "train_loss": 1.06656371995219,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 169,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 42.53174498653724,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0818207307737016,
        "time": 4.285670042037964,
        "additional_info": {
            "duration": 4.27687931060791,
            "num_run": 170,
            "train_loss": 1.0768682658008177,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 170,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007997455894260718,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0987512461707698,
        "time": 11.007667064666748,
        "additional_info": {
            "duration": 10.997813940048218,
            "num_run": 171,
            "train_loss": 1.0803928711863213,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 171,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011360444443958448,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0018098707634502114,
            "feature_preprocessor:kitchen_sinks:n_components": 372
        },
        "cost": 0.0,
        "time": 0.1642298698425293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 172,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008741748962634063,
            "feature_preprocessor:kitchen_sinks:gamma": 0.004042039845212017,
            "feature_preprocessor:kitchen_sinks:n_components": 1287
        },
        "cost": 0.0,
        "time": 0.17049908638000488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 173,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007772667909981632,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1367,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2423019409179688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 174,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1632,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.163724899291992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 175,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02358190192617522,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1680,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.190948724746704,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 176,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007176060315836039,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0003350092557331161,
            "feature_preprocessor:kitchen_sinks:n_components": 80
        },
        "cost": 0.0,
        "time": 0.44303107261657715,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 177,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8352765881283931,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07922373358720441,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0262703877331582,
            "feature_preprocessor:kitchen_sinks:n_components": 595
        },
        "cost": 0.0,
        "time": 0.15294814109802246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 178,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 41.35428265192899,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0839849075122532,
        "time": 2.3410286903381348,
        "additional_info": {
            "duration": 2.332261323928833,
            "num_run": 179,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 179,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010639778393979652,
            "feature_preprocessor:kitchen_sinks:gamma": 1.1259325125667912,
            "feature_preprocessor:kitchen_sinks:n_components": 583
        },
        "cost": 0.0,
        "time": 0.14722704887390137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 180,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1713,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.112107038497925,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 181,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017953668221457435,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 835,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.147413730621338,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 182,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011119252072506346,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1463,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1382699012756348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 183,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04358433358518785,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0839849075122532,
        "time": 9.820683717727661,
        "additional_info": {
            "duration": 9.812198877334595,
            "num_run": 184,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 184,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003435649002259499,
            "feature_preprocessor:kitchen_sinks:gamma": 1.0950672745770746,
            "feature_preprocessor:kitchen_sinks:n_components": 392
        },
        "cost": 0.0,
        "time": 0.47168397903442383,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 185,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 675,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.215904951095581,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 186,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002589246735314047,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2158254781983433,
        "time": 13.142879009246826,
        "additional_info": {
            "duration": 13.133805990219116,
            "num_run": 187,
            "train_loss": 1.0751940929833446,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 187,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1612,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.211491107940674,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 188,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1737,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.305468797683716,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 189,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008082293270978327,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1581,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.226547956466675,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 190,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0059887192745340274,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1736,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2449347972869873,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 191,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03843789738594497,
            "feature_preprocessor:select_percentile_classification:percentile": 49.75006303948288,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0948478168285833,
        "time": 2.409795045852661,
        "additional_info": {
            "duration": 2.4008989334106445,
            "num_run": 192,
            "train_loss": 1.0788530873438975,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 192,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13026354804879076,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9013653549451784,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15624143498554263,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0942045673573306,
        "time": 4.429157972335815,
        "additional_info": {
            "duration": 4.419342756271362,
            "num_run": 193,
            "train_loss": 1.0714644475890467,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 193,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008723319320135385,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 707,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1513190269470215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 194,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7323923934375316,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09790803477530499,
            "feature_preprocessor:kitchen_sinks:gamma": 0.6914062789228976,
            "feature_preprocessor:kitchen_sinks:n_components": 351
        },
        "cost": 0.0,
        "time": 0.16399312019348145,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 195,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009045591342339761,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1251540273680962,
        "time": 4.375046253204346,
        "additional_info": {
            "duration": 4.366370677947998,
            "num_run": 196,
            "train_loss": 1.0699976620870404,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 196,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010419300067424775,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1466,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.119376741460361,
        "time": 4.9130449295043945,
        "additional_info": {
            "duration": 4.903653860092163,
            "num_run": 197,
            "train_loss": 1.0683281838829126,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 197,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017129730844952316,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1528,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1943130493164062,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 198,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 365,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1578471660614014,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 199,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013872142418390502,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1648,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2631149291992188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 200,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015294264678434282,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1361,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.245882034301758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 201,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.127164546706497,
        "time": 21.687577962875366,
        "additional_info": {
            "duration": 21.677508115768433,
            "num_run": 202,
            "train_loss": 1.0666406715002108,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 202,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01978383823843691,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0839849075122532,
        "time": 10.081880807876587,
        "additional_info": {
            "duration": 10.073119878768921,
            "num_run": 203,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 203,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1306750213808685,
        "time": 4.497477769851685,
        "additional_info": {
            "duration": 4.488713979721069,
            "num_run": 204,
            "train_loss": 1.0712476710468886,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 204,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1789,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.252840280532837,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 205,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04900208691254784,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 441,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 43.12913797489067,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1330465723889003,
        "time": 2.9906129837036133,
        "additional_info": {
            "duration": 2.9817001819610596,
            "num_run": 206,
            "train_loss": 1.0684048892520412,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 206,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1499,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2671589851379395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 207,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 365,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1722960472106934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 208,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1667096957427425,
            "feature_preprocessor:kitchen_sinks:gamma": 0.005077710207253003,
            "feature_preprocessor:kitchen_sinks:n_components": 1522
        },
        "cost": 0.0,
        "time": 0.141082763671875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 209,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005256642946570009,
            "feature_preprocessor:select_percentile_classification:percentile": 1.3532612196509237,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0839849075122532,
        "time": 2.2193830013275146,
        "additional_info": {
            "duration": 2.2106308937072754,
            "num_run": 210,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 210,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.048299799142400776,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1438,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.126593493254899,
        "time": 23.935699224472046,
        "additional_info": {
            "duration": 23.92516803741455,
            "num_run": 211,
            "train_loss": 1.0592668541220727,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 211,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005175255637726564,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.135410533059914,
        "time": 21.71659803390503,
        "additional_info": {
            "duration": 21.706865072250366,
            "num_run": 212,
            "train_loss": 1.0636138466290461,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 212,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.43530192603974777,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0858577084136936,
        "time": 24.615169048309326,
        "additional_info": {
            "duration": 24.605319261550903,
            "num_run": 213,
            "train_loss": 1.0505671869101458,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 213,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 57.36314023567942,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.080878417096752,
        "time": 2.5078060626983643,
        "additional_info": {
            "duration": 2.498878240585327,
            "num_run": 214,
            "train_loss": 1.0762457317170127,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 214,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1662,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.10648222750495048,
            "feature_preprocessor:kitchen_sinks:n_components": 5071
        },
        "cost": 0.0,
        "time": 0.3113870620727539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 215,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00028177413626380806,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.846404100004499,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13612492636924187,
            "feature_preprocessor:kitchen_sinks:gamma": 0.017834108765978688,
            "feature_preprocessor:kitchen_sinks:n_components": 683
        },
        "cost": 0.0,
        "time": 0.16132402420043945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 216,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 557,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.02348668941960978,
            "feature_preprocessor:kitchen_sinks:n_components": 514
        },
        "cost": 0.0,
        "time": 0.2557828426361084,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 217,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010881889192957996,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0984583951131222,
        "time": 3.5032849311828613,
        "additional_info": {
            "duration": 3.493941068649292,
            "num_run": 218,
            "train_loss": 1.0800816041444188,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 218,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7074603493919174,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2595646471636266,
            "feature_preprocessor:kitchen_sinks:gamma": 4.488015019053857e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 948
        },
        "cost": 0.0,
        "time": 0.1506340503692627,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 219,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 903,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1320614608454882,
        "time": 4.404078245162964,
        "additional_info": {
            "duration": 4.394857883453369,
            "num_run": 220,
            "train_loss": 1.0706721975787863,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 220,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1860,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.328688859939575,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 221,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013251038224656102,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 448,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1984031200408936,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 222,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014775591353276582,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0893862291881273,
        "time": 4.329774856567383,
        "additional_info": {
            "duration": 4.320833206176758,
            "num_run": 223,
            "train_loss": 1.0730054651949967,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 223,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1669609264952476,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 430,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0002699465353054388,
            "feature_preprocessor:kitchen_sinks:n_components": 95
        },
        "cost": 0.0,
        "time": 0.22670674324035645,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 224,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02757478155754358,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 286,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.167271137237549,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 225,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012090428710521703,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0839849075122532,
        "time": 8.861906051635742,
        "additional_info": {
            "duration": 8.853290796279907,
            "num_run": 226,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 226,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 368,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.182555913925171,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 227,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0977010903234117,
        "time": 25.638206958770752,
        "additional_info": {
            "duration": 25.6283860206604,
            "num_run": 228,
            "train_loss": 1.0539151604076884,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 228,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004412567622372355,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7586975289700948,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.20767271282045077,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0002639577221496776,
            "feature_preprocessor:kitchen_sinks:n_components": 3889
        },
        "cost": 0.0,
        "time": 0.2048492431640625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 229,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1531,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1293993829017126,
        "time": 22.08858585357666,
        "additional_info": {
            "duration": 22.077747106552124,
            "num_run": 230,
            "train_loss": 1.0679269949960988,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 230,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1741,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.287553071975708,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 231,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 356,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.195099353790283,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 232,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016930510308137806,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1467,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.324454722856412,
        "time": 10.558036088943481,
        "additional_info": {
            "duration": 10.54819917678833,
            "num_run": 233,
            "train_loss": 1.0788260360760367,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 233,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 6.104478544278581,
            "feature_preprocessor:kitchen_sinks:n_components": 2272
        },
        "cost": 0.0,
        "time": 0.15327191352844238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 234,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02757478155754358,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 102,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.204376220703125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 235,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1187,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.212799310684204,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 236,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003231557435457127,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0717255202077713,
        "time": 23.160449743270874,
        "additional_info": {
            "duration": 23.15025496482849,
            "num_run": 237,
            "train_loss": 1.0760170984211106,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 237,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023570091434868864,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 408,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.17666702917135496,
            "feature_preprocessor:kitchen_sinks:n_components": 67
        },
        "cost": 0.0,
        "time": 0.2532968521118164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 238,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017406097754537157,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1309,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2569668292999268,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 239,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007505306291017361,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0020769260190149704,
            "feature_preprocessor:kitchen_sinks:n_components": 666
        },
        "cost": 0.0,
        "time": 0.1487562656402588,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 240,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00326915515659081,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 721,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1752560138702393,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 241,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008782809836178389,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1583,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2071547508239746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 242,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017025654934786062,
            "feature_preprocessor:select_percentile_classification:percentile": 72.9683007135934,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1055412654568815,
        "time": 2.510178804397583,
        "additional_info": {
            "duration": 2.5014572143554688,
            "num_run": 243,
            "train_loss": 1.0643807743618223,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 243,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0377109634319703,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 360,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.235672950744629,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 244,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7581058625929843,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.28509621653608497,
            "feature_preprocessor:kitchen_sinks:gamma": 0.16596121643135742,
            "feature_preprocessor:kitchen_sinks:n_components": 1606
        },
        "cost": 0.0,
        "time": 0.178239107131958,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 245,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.013960758373569781,
            "feature_preprocessor:kitchen_sinks:n_components": 151
        },
        "cost": 0.0,
        "time": 0.1726846694946289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 246,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1693,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.233412027359009,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 247,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 96.28652974622773,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0839849075122532,
        "time": 2.383145809173584,
        "additional_info": {
            "duration": 2.3743720054626465,
            "num_run": 248,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 248,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.033913072338830466,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1525,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.0998971462249756,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 249,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1816,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.187941074371338,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 250,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0023806081235280443,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0984583951131222,
        "time": 3.45705509185791,
        "additional_info": {
            "duration": 3.4482438564300537,
            "num_run": 251,
            "train_loss": 1.0800816041444188,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 251,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 53.27192455382712,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0659362726408754,
        "time": 2.4335198402404785,
        "additional_info": {
            "duration": 2.4239401817321777,
            "num_run": 252,
            "train_loss": 1.0561672770893826,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 252,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004482525472075935,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1792,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1368481171601532,
        "time": 4.4126551151275635,
        "additional_info": {
            "duration": 4.403609037399292,
            "num_run": 253,
            "train_loss": 1.0717001199359006,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 253,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0984583951131222,
        "time": 3.701630115509033,
        "additional_info": {
            "duration": 3.692244052886963,
            "num_run": 254,
            "train_loss": 1.0800659172725178,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 254,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1819,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.011653797396337217,
            "feature_preprocessor:kitchen_sinks:n_components": 55
        },
        "cost": 0.0,
        "time": 0.30643200874328613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 255,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06245611573530542,
            "feature_preprocessor:kitchen_sinks:gamma": 3.40440368155909e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 351
        },
        "cost": 0.0,
        "time": 0.1617729663848877,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 256,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010281952693823686,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1802,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.200148105621338,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 257,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 33,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 8.001000150536812e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 180
        },
        "cost": 0.0,
        "time": 0.22859597206115723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 258,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09909999611000941,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1009986973058654,
        "time": 11.318382263183594,
        "additional_info": {
            "duration": 11.308933973312378,
            "num_run": 259,
            "train_loss": 1.080323453916103,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 259,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018282380540367193,
            "feature_preprocessor:kitchen_sinks:gamma": 0.003306027117268562,
            "feature_preprocessor:kitchen_sinks:n_components": 452
        },
        "cost": 0.0,
        "time": 0.14480805397033691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 260,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006838987705928571,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0014273168938836785,
            "feature_preprocessor:kitchen_sinks:n_components": 636
        },
        "cost": 0.0,
        "time": 0.14864206314086914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 261,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.096344740396345,
        "time": 13.296244859695435,
        "additional_info": {
            "duration": 13.286696910858154,
            "num_run": 262,
            "train_loss": 1.0770581141645612,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 262,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8578630262363607,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2321308342896216,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0839849075122532,
        "time": 9.79181694984436,
        "additional_info": {
            "duration": 9.782930135726929,
            "num_run": 263,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 263,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020640634759899493,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 155,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 5.4093976008280826e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.23964214324951172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 264,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1134,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.15340233716450116,
            "feature_preprocessor:kitchen_sinks:n_components": 499
        },
        "cost": 0.0,
        "time": 0.3034687042236328,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 265,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 15,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2014710903167725,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 266,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.775140556406722,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.018025940558586084,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1709650593249736,
        "time": 21.238498210906982,
        "additional_info": {
            "duration": 21.22999906539917,
            "num_run": 267,
            "train_loss": 1.170689222423903,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 267,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.24153995516005533,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1602,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00015546470090403692,
            "feature_preprocessor:kitchen_sinks:n_components": 5857
        },
        "cost": 0.0,
        "time": 0.27523255348205566,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 268,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 77.25449008350188,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.14877141180807,
        "time": 2.381768226623535,
        "additional_info": {
            "duration": 2.3723220825195312,
            "num_run": 269,
            "train_loss": 1.078947454754196,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 269,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1465730074655058,
        "time": 27.563138008117676,
        "additional_info": {
            "duration": 27.553240060806274,
            "num_run": 270,
            "train_loss": 1.0563020353327701,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 270,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15291807325116036,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1087,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.208303928375244,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 271,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10346551279223207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1575,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.242582082748413,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 272,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010689337267084745,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1407,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1813199520111084,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 273,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1665,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.340474843978882,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 274,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008785349041211178,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7802257368131407,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24149915480641343,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0021647324830694936,
            "feature_preprocessor:kitchen_sinks:n_components": 90
        },
        "cost": 0.0,
        "time": 0.13502192497253418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 275,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 5.4721777829599734e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 3544
        },
        "cost": 0.0,
        "time": 0.4361569881439209,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 276,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 45.47330692203159,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0948478168285833,
        "time": 4.292712926864624,
        "additional_info": {
            "duration": 4.283715009689331,
            "num_run": 277,
            "train_loss": 1.0788530873438975,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 277,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010797937437870157,
            "feature_preprocessor:kitchen_sinks:gamma": 0.1572561543575672,
            "feature_preprocessor:kitchen_sinks:n_components": 301
        },
        "cost": 0.0,
        "time": 0.44333386421203613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 278,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 213,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.181198835372925,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 279,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.033497044054420236,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1801,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.208527088165283,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 280,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007886869399179677,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9303303614696485,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25470645693948435,
            "feature_preprocessor:kitchen_sinks:gamma": 0.10370713493648871,
            "feature_preprocessor:kitchen_sinks:n_components": 533
        },
        "cost": 0.0,
        "time": 0.1792302131652832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 281,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1823,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 96.24219551978193,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0839849075122532,
        "time": 2.6333980560302734,
        "additional_info": {
            "duration": 2.623591899871826,
            "num_run": 282,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 282,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002086861856540513,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1712,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.209012031555176,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 283,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22467521756917316,
            "feature_preprocessor:select_percentile_classification:percentile": 76.6549954348041,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.102437065250987,
        "time": 2.437934160232544,
        "additional_info": {
            "duration": 2.428277015686035,
            "num_run": 284,
            "train_loss": 1.0800527007967353,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 284,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 376,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.030010854406662013,
            "feature_preprocessor:kitchen_sinks:n_components": 461
        },
        "cost": 0.0,
        "time": 0.21041202545166016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 285,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021741478340844147,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 844,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1901307106018066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 286,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7970892269078561,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17345618108959499,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0926613973752854,
        "time": 4.461671829223633,
        "additional_info": {
            "duration": 4.451707124710083,
            "num_run": 287,
            "train_loss": 1.0781339616325671,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 287,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1041,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2392282485961914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 288,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013345650287113642,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1642,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.214325189590454,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 289,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019555942915553987,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 117,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1914899349212646,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 290,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02030233629424293,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 376,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1333837509155273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 291,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011709483858811799,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.719090181808262,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23185163229324263,
            "feature_preprocessor:kitchen_sinks:gamma": 0.02223351088320254,
            "feature_preprocessor:kitchen_sinks:n_components": 155
        },
        "cost": 0.0,
        "time": 0.1615159511566162,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 292,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016572273832730734,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1939,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1874499320983887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 293,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010992571336015714,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9376262623400862,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13536696400134157,
            "feature_preprocessor:select_percentile_classification:percentile": 50.34145902134344,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2850822282527026,
        "time": 4.346039772033691,
        "additional_info": {
            "duration": 4.337170839309692,
            "num_run": 294,
            "train_loss": 1.0708710630318168,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 294,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03292439202856721,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0945445476429263,
        "time": 4.225645065307617,
        "additional_info": {
            "duration": 4.216063022613525,
            "num_run": 295,
            "train_loss": 1.081099644917058,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 295,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7171258696272231,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07225337300744572,
            "feature_preprocessor:kitchen_sinks:gamma": 0.2980866723335739,
            "feature_preprocessor:kitchen_sinks:n_components": 5870
        },
        "cost": 0.0,
        "time": 0.1512451171875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 296,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002315990375388073,
            "feature_preprocessor:select_percentile_classification:percentile": 71.21857880303281,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1997442423455358,
        "time": 2.3589789867401123,
        "additional_info": {
            "duration": 2.3500819206237793,
            "num_run": 297,
            "train_loss": 1.0638472976277398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 297,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1633,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 67.1889838403558,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0839849075122532,
        "time": 2.615767002105713,
        "additional_info": {
            "duration": 2.6068649291992188,
            "num_run": 298,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 298,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3977386260086313,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1165,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.003590226056524687,
            "feature_preprocessor:kitchen_sinks:n_components": 3824
        },
        "cost": 0.0,
        "time": 0.2956230640411377,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 299,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017851055686855195,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 323,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.171326160430908,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 300,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1000,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 3.5049427125307876e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 1248
        },
        "cost": 0.0,
        "time": 0.24940991401672363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 301,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9432949014676222,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13887814140166685,
            "feature_preprocessor:kitchen_sinks:gamma": 0.026431459777647735,
            "feature_preprocessor:kitchen_sinks:n_components": 63
        },
        "cost": 0.0,
        "time": 0.1896369457244873,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 302,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 556,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 4.388637572594787,
            "feature_preprocessor:kitchen_sinks:n_components": 6635
        },
        "cost": 0.0,
        "time": 0.24135088920593262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 303,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8191520052485556,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0770502337638853,
            "feature_preprocessor:select_percentile_classification:percentile": 86.03097000388736,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2465119624895054,
        "time": 4.358309030532837,
        "additional_info": {
            "duration": 4.349204063415527,
            "num_run": 304,
            "train_loss": 1.065292218833015,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 304,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 4.562054761430068e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 7301
        },
        "cost": 0.0,
        "time": 0.46034789085388184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 305,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08155387569462753,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0030080952246238865,
            "feature_preprocessor:kitchen_sinks:n_components": 1988
        },
        "cost": 0.0,
        "time": 0.14759516716003418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 306,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023205435915171498,
            "feature_preprocessor:kitchen_sinks:gamma": 0.07915553949091836,
            "feature_preprocessor:kitchen_sinks:n_components": 1964
        },
        "cost": 0.0,
        "time": 0.4181938171386719,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 307,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 13,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1428279876708984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 308,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1613,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00021483236062123546,
            "feature_preprocessor:kitchen_sinks:n_components": 162
        },
        "cost": 0.0,
        "time": 0.24225878715515137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 309,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 171,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 6.9281201090451665,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1735223528734717,
        "time": 2.6625869274139404,
        "additional_info": {
            "duration": 2.653564929962158,
            "num_run": 310,
            "train_loss": 1.0648289007748932,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 310,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 101,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 5.176401183096713e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 814
        },
        "cost": 0.0,
        "time": 0.24320697784423828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 311,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10623601042609339,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1683,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00018223956782012116,
            "feature_preprocessor:kitchen_sinks:n_components": 52
        },
        "cost": 0.0,
        "time": 0.2339491844177246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 312,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1510,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.23978328704834,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 313,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.050766536204705275,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1902,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2503092288970947,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 314,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004874220779445106,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.12609373953287,
        "time": 4.583387136459351,
        "additional_info": {
            "duration": 4.573718070983887,
            "num_run": 315,
            "train_loss": 1.064834952241211,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 315,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.043213023151413565,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1780,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2990667819976807,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 316,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.6409641387164956,
            "feature_preprocessor:kitchen_sinks:n_components": 129
        },
        "cost": 0.0,
        "time": 0.1639690399169922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 317,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8086741241913443,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.019152140724472952,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1750331886661807,
        "time": 21.916953802108765,
        "additional_info": {
            "duration": 21.907270193099976,
            "num_run": 318,
            "train_loss": 1.1679563718218093,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 318,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8934649046492372,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.007372350552111922,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0839849075122532,
        "time": 10.229883909225464,
        "additional_info": {
            "duration": 10.220975875854492,
            "num_run": 319,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 319,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7269300273515137,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18976930389079885,
            "feature_preprocessor:select_percentile_classification:percentile": 80.38374126493505,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2289907561522997,
        "time": 4.340641975402832,
        "additional_info": {
            "duration": 4.331135988235474,
            "num_run": 320,
            "train_loss": 1.0783488832258366,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 320,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004034599883072066,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1286,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.15851441577111317,
            "feature_preprocessor:kitchen_sinks:n_components": 2765
        },
        "cost": 0.0,
        "time": 0.303053617477417,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 321,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.217607021331787,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 322,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 81.85450890122112,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1656403909257453,
        "time": 4.548384189605713,
        "additional_info": {
            "duration": 4.538763999938965,
            "num_run": 323,
            "train_loss": 1.068836710476915,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 323,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018186745026622296,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8979651992403468,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08196898702403771,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0162282282396204,
            "feature_preprocessor:kitchen_sinks:n_components": 176
        },
        "cost": 0.0,
        "time": 0.1517040729522705,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 324,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003175832601642777,
            "feature_preprocessor:select_percentile_classification:percentile": 11.000443745952923,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0834660097484805,
        "time": 4.2426722049713135,
        "additional_info": {
            "duration": 4.233927965164185,
            "num_run": 325,
            "train_loss": 1.087414784510576,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 325,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011916080665530827,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1973,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2035152912139893,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 326,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8900678088258287,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2827268547975308,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1856596661408727,
        "time": 22.158965826034546,
        "additional_info": {
            "duration": 22.15008282661438,
            "num_run": 327,
            "train_loss": 1.163483019844439,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 327,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1810,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.274847984313965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 328,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024312232994781427,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.102437065250987,
        "time": 13.031410932540894,
        "additional_info": {
            "duration": 13.022159099578857,
            "num_run": 329,
            "train_loss": 1.0800213270529333,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 329,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9894656828975319,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09454299196134522,
            "feature_preprocessor:select_percentile_classification:percentile": 79.02373616842794,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2007028722732376,
        "time": 2.592007875442505,
        "additional_info": {
            "duration": 2.582737922668457,
            "num_run": 330,
            "train_loss": 1.0727014862520046,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 330,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 10,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.209030866622925,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 331,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 630,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2203660011291504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 332,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 258,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.30473789249619504,
            "feature_preprocessor:kitchen_sinks:n_components": 1604
        },
        "cost": 0.0,
        "time": 0.21781301498413086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 333,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008790622064501402,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1376,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1783597469329834,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 334,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16685393951116184,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7172536527611864,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1379025902150636,
            "feature_preprocessor:kitchen_sinks:gamma": 7.753326983531762,
            "feature_preprocessor:kitchen_sinks:n_components": 3791
        },
        "cost": 0.0,
        "time": 0.16144680976867676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 335,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1252557864860115,
        "time": 4.482816696166992,
        "additional_info": {
            "duration": 4.440891981124878,
            "num_run": 336,
            "train_loss": 1.0704814847198547,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 336,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004611536695490087,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0956192805492257,
        "time": 18.55692481994629,
        "additional_info": {
            "duration": 18.548290967941284,
            "num_run": 337,
            "train_loss": 1.0750311727980157,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 337,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 444,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 4.369446991987362,
            "feature_preprocessor:kitchen_sinks:n_components": 2963
        },
        "cost": 0.0,
        "time": 0.22312498092651367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 338,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10717553261409501,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1463,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 1.5397854079362094,
            "feature_preprocessor:kitchen_sinks:n_components": 7006
        },
        "cost": 0.0,
        "time": 0.27505016326904297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 339,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1057,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1099813115582895,
        "time": 23.481549978256226,
        "additional_info": {
            "duration": 23.47202777862549,
            "num_run": 340,
            "train_loss": 1.059784520894808,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 340,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09348322991710602,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1336,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.24786114692688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 341,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1745,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2897729873657227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 342,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2402821287548735,
        "time": 2.9746248722076416,
        "additional_info": {
            "duration": 2.9655098915100098,
            "num_run": 343,
            "train_loss": 1.073092793554343,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 343,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.122916905614519,
        "time": 4.172014951705933,
        "additional_info": {
            "duration": 4.163313150405884,
            "num_run": 344,
            "train_loss": 1.0673795603804919,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 344,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 6.665443339320585,
            "feature_preprocessor:kitchen_sinks:n_components": 1161
        },
        "cost": 0.0,
        "time": 0.1662139892578125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 345,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1926,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2005350589752197,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 346,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00025140872221902607,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1881,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.002164631504315496,
            "feature_preprocessor:kitchen_sinks:n_components": 1313
        },
        "cost": 0.0,
        "time": 0.27048778533935547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 347,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006173651471555009,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1861,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2686288356781006,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 348,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1828,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.199627637863159,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 349,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011916080665530827,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1934,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1963210105895996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 350,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1435,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.15803538848354035,
            "feature_preprocessor:kitchen_sinks:n_components": 51
        },
        "cost": 0.0,
        "time": 0.3349120616912842,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 351,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2294174852229345,
            "feature_preprocessor:kitchen_sinks:gamma": 0.023035114264486335,
            "feature_preprocessor:kitchen_sinks:n_components": 93
        },
        "cost": 0.0,
        "time": 0.13396382331848145,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 352,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 1.5713259545120877,
            "feature_preprocessor:kitchen_sinks:n_components": 404
        },
        "cost": 0.0,
        "time": 0.11585831642150879,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 353,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1018506471241105,
        "time": 4.041150808334351,
        "additional_info": {
            "duration": 4.031934976577759,
            "num_run": 354,
            "train_loss": 1.0631539865516775,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 354,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015253635530309829,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1086,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2955570220947266,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 355,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.7200852349999354,
            "feature_preprocessor:kitchen_sinks:n_components": 219
        },
        "cost": 0.0,
        "time": 0.1168050765991211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 356,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1212826729613474,
        "time": 4.708387136459351,
        "additional_info": {
            "duration": 4.699559926986694,
            "num_run": 357,
            "train_loss": 1.0711271168639174,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 357,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1458,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 39.84535720201162,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1946834120524061,
        "time": 2.6336398124694824,
        "additional_info": {
            "duration": 2.6239707469940186,
            "num_run": 358,
            "train_loss": 1.0704681451546265,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 358,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0051753370582506356,
            "feature_preprocessor:kitchen_sinks:n_components": 159
        },
        "cost": 0.0,
        "time": 0.14613819122314453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 359,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03755265091872336,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1148,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2126972675323486,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 360,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8117785454501937,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21088332409807717,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0998838321645497,
        "time": 4.603353977203369,
        "additional_info": {
            "duration": 4.593687057495117,
            "num_run": 361,
            "train_loss": 1.073800185601376,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 361,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010954164805421308,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 59,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2138500213623047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 362,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1946,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.236851930618286,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 363,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 10,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.119981050491333,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 364,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12924483656568925,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9068362704729998,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2537601150827836,
            "feature_preprocessor:kitchen_sinks:gamma": 0.8793740201613107,
            "feature_preprocessor:kitchen_sinks:n_components": 423
        },
        "cost": 0.0,
        "time": 0.18819093704223633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 365,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.43070314364269974,
            "feature_preprocessor:kitchen_sinks:n_components": 77
        },
        "cost": 0.0,
        "time": 0.1326768398284912,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 366,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1955,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2315151691436768,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 367,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013978288235980115,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1092072830319986,
        "time": 25.325570106506348,
        "additional_info": {
            "duration": 25.31692409515381,
            "num_run": 368,
            "train_loss": 1.0627445219813192,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 368,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2060015348247334,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 415,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.1914502589539884e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 377
        },
        "cost": 0.0,
        "time": 0.27219510078430176,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 369,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10346551279223207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1454,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2422797679901123,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 370,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005262584180866204,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0839849075122532,
        "time": 9.991840124130249,
        "additional_info": {
            "duration": 9.983000993728638,
            "num_run": 371,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 371,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.41690268017325155,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1171,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.1905231862038772,
            "feature_preprocessor:kitchen_sinks:n_components": 325
        },
        "cost": 0.0,
        "time": 0.252608060836792,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 372,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1130,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.004202384546176722,
            "feature_preprocessor:kitchen_sinks:n_components": 1567
        },
        "cost": 0.0,
        "time": 0.23474526405334473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 373,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1803,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.4716438903942731,
            "feature_preprocessor:kitchen_sinks:n_components": 133
        },
        "cost": 0.0,
        "time": 0.28034257888793945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 374,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015233559341841998,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1634,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.280925750732422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 375,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1247741369565836,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9894794671787783,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06387364516303067,
            "feature_preprocessor:kitchen_sinks:gamma": 0.011977500184389912,
            "feature_preprocessor:kitchen_sinks:n_components": 72
        },
        "cost": 0.0,
        "time": 0.17015290260314941,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 376,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1409681396411873,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1667,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2014501094818115,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 377,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001600673909609605,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.127335054224754,
        "time": 4.44007134437561,
        "additional_info": {
            "duration": 4.4313530921936035,
            "num_run": 378,
            "train_loss": 1.0644766245836053,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 378,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1717,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1800413131713867,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 379,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.115948906489382,
        "time": 20.001113176345825,
        "additional_info": {
            "duration": 19.991491079330444,
            "num_run": 380,
            "train_loss": 1.0551982721017152,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 380,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1908,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.3212451934814453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 381,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009380824891548742,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1975,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.205965995788574,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 382,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.053900757038315754,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1987,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.232919692993164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 383,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2373146813984415,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 135,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1432394430297292,
        "time": 4.329867839813232,
        "additional_info": {
            "duration": 4.320674180984497,
            "num_run": 384,
            "train_loss": 1.0668643640038753,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 384,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.8521277891409937,
            "feature_preprocessor:kitchen_sinks:n_components": 56
        },
        "cost": 0.0,
        "time": 0.17449283599853516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 385,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1606,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2441296577453613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 386,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 585,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00013666423609213948,
            "feature_preprocessor:kitchen_sinks:n_components": 54
        },
        "cost": 0.0,
        "time": 0.28464198112487793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 387,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.0740609169006348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 388,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.083155061403738e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 441
        },
        "cost": 0.0,
        "time": 0.4707651138305664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 389,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006825134226015353,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1062,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 2.4531810920058,
            "feature_preprocessor:kitchen_sinks:n_components": 210
        },
        "cost": 0.0,
        "time": 0.2659480571746826,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 390,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 40,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1875040531158447,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 391,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 879,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1613604964768403,
        "time": 18.41334295272827,
        "additional_info": {
            "duration": 18.40421414375305,
            "num_run": 392,
            "train_loss": 1.0648076547944583,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 392,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015283931670381665,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7789395761289479,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27893834043834054,
            "feature_preprocessor:select_percentile_classification:percentile": 98.82101406367157,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2037099560339783,
        "time": 2.646193742752075,
        "additional_info": {
            "duration": 2.637132167816162,
            "num_run": 393,
            "train_loss": 1.0812229156750397,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 393,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1499,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.210218906402588,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 394,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 79.73552915989221,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0889396226987609,
        "time": 4.2958197593688965,
        "additional_info": {
            "duration": 4.286147117614746,
            "num_run": 395,
            "train_loss": 1.0826632682254815,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 395,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.30458802683831476,
            "feature_preprocessor:kitchen_sinks:gamma": 3.543521799066533e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 1678
        },
        "cost": 0.0,
        "time": 0.1471719741821289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 396,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002832548962893659,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 975,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0032242845905961744,
            "feature_preprocessor:kitchen_sinks:n_components": 70
        },
        "cost": 0.0,
        "time": 0.22138285636901855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 397,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04581293427613825,
            "feature_preprocessor:select_percentile_classification:percentile": 50.30839416482553,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1261376362695215,
        "time": 2.465363025665283,
        "additional_info": {
            "duration": 2.456545114517212,
            "num_run": 398,
            "train_loss": 1.068753335325172,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 398,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 286,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2607929706573486,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 399,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004708811517716726,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1716,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 9.688187848349879e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 3201
        },
        "cost": 0.0,
        "time": 0.2627828121185303,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 400,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 941,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 6.381836646599281e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 2714
        },
        "cost": 0.0,
        "time": 0.25469017028808594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 401,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06784085114093373,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9583885803707868,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15270708681356476,
            "feature_preprocessor:select_percentile_classification:percentile": 62.23637177290612,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1640031520600926,
        "time": 2.517585277557373,
        "additional_info": {
            "duration": 2.507323980331421,
            "num_run": 402,
            "train_loss": 1.0723440230895869,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 402,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.27209030930362493,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9870705348574189,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1397894315721195,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0510483378728951,
            "feature_preprocessor:kitchen_sinks:n_components": 386
        },
        "cost": 0.0,
        "time": 0.179548978805542,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 403,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005460538596518616,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 999,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0869829424584068,
            "feature_preprocessor:kitchen_sinks:n_components": 150
        },
        "cost": 0.0,
        "time": 0.24944686889648438,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 404,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0931309945155291,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1643,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2509138584136963,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 405,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 379,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 50.00750449066263,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1319521378747903,
        "time": 2.992177724838257,
        "additional_info": {
            "duration": 2.9823732376098633,
            "num_run": 406,
            "train_loss": 1.0590363687463482,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 406,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20305734374505047,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1250233370595486,
        "time": 19.657352924346924,
        "additional_info": {
            "duration": 19.647841215133667,
            "num_run": 407,
            "train_loss": 1.0594709065462327,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 407,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 85.84567501626562,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.194095980087801,
        "time": 4.246528148651123,
        "additional_info": {
            "duration": 4.237208843231201,
            "num_run": 408,
            "train_loss": 1.0688638848342218,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 408,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017775363627865916,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 212,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00011672588335926801,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.2532920837402344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 409,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003388263804553645,
            "feature_preprocessor:select_percentile_classification:percentile": 33.733663858012804,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0839849075122532,
        "time": 2.447166919708252,
        "additional_info": {
            "duration": 2.4381649494171143,
            "num_run": 410,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 410,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008027258217208644,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1646,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.212132215499878,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 411,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024016698411192996,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.790035677140567,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2562573011864301,
            "feature_preprocessor:select_percentile_classification:percentile": 27.98725849642838,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.220595098536644,
        "time": 2.4832770824432373,
        "additional_info": {
            "duration": 2.4744229316711426,
            "num_run": 412,
            "train_loss": 1.0776165410387237,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 412,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 177,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 5.4093976008280826e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.2637362480163574,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 413,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002385589756279682,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 580,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.5954735119051533,
            "feature_preprocessor:kitchen_sinks:n_components": 110
        },
        "cost": 0.0,
        "time": 0.24787402153015137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 414,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2664356104076306,
        "time": 2.916278839111328,
        "additional_info": {
            "duration": 2.907378911972046,
            "num_run": 415,
            "train_loss": 1.0697605069287017,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 415,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03153298907443315,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 164,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1780009269714355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 416,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016832851492947613,
            "feature_preprocessor:select_percentile_classification:percentile": 25.44563805514942,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0839849075122532,
        "time": 4.245498180389404,
        "additional_info": {
            "duration": 4.235486030578613,
            "num_run": 417,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 417,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0931309945155291,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1643,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2546229362487793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 418,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1047,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2416000366210938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 419,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1885,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.182979106903076,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 420,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 400,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.03154869943653907,
            "feature_preprocessor:kitchen_sinks:n_components": 3577
        },
        "cost": 0.0,
        "time": 0.23743915557861328,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 421,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014963625253328328,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.953526448538006,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12297674880003574,
            "feature_preprocessor:kitchen_sinks:gamma": 3.607363522805387,
            "feature_preprocessor:kitchen_sinks:n_components": 96
        },
        "cost": 0.0,
        "time": 0.1794288158416748,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 422,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06567857919627698,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1184493924009231,
        "time": 20.371232986450195,
        "additional_info": {
            "duration": 20.361756801605225,
            "num_run": 423,
            "train_loss": 1.0563490959484734,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 423,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1660,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2339377403259277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 424,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1474087637004937,
        "time": 4.032379150390625,
        "additional_info": {
            "duration": 4.023113012313843,
            "num_run": 425,
            "train_loss": 1.0713409277831065,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 425,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008464863455759053,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 44,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.144767999649048,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 426,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025485942302731258,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 262,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.015306928281660975,
            "feature_preprocessor:kitchen_sinks:n_components": 3473
        },
        "cost": 0.0,
        "time": 0.2351701259613037,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 427,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 10,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.232858180999756,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 428,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1866,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.2555160285631925,
            "feature_preprocessor:kitchen_sinks:n_components": 78
        },
        "cost": 0.0,
        "time": 0.27945494651794434,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 429,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0003789368162640793,
            "feature_preprocessor:kitchen_sinks:n_components": 53
        },
        "cost": 0.0,
        "time": 0.14294195175170898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 430,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.243177890777588,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 431,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004493862161213255,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 132,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1154749393463135,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 432,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021431132773556128,
            "feature_preprocessor:select_percentile_classification:percentile": 28.862292339660755,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1344973025108502,
        "time": 2.760852098464966,
        "additional_info": {
            "duration": 2.7519519329071045,
            "num_run": 433,
            "train_loss": 1.0769725147955915,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 433,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 125,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 4.446900742725928,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.22886180877685547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 434,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004308963325603937,
            "feature_preprocessor:kitchen_sinks:gamma": 0.025163842125876273,
            "feature_preprocessor:kitchen_sinks:n_components": 9853
        },
        "cost": 0.0,
        "time": 0.13576912879943848,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 435,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001105098859350879,
            "feature_preprocessor:kitchen_sinks:gamma": 0.029020379872205623,
            "feature_preprocessor:kitchen_sinks:n_components": 2043
        },
        "cost": 0.0,
        "time": 0.1462390422821045,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 436,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9722139634790913,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13365701385036274,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0921863954196567,
        "time": 4.457958221435547,
        "additional_info": {
            "duration": 4.449019908905029,
            "num_run": 437,
            "train_loss": 1.0769359540806598,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 437,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006599945106547521,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 563,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.3669710049781118,
            "feature_preprocessor:kitchen_sinks:n_components": 352
        },
        "cost": 0.0,
        "time": 0.2567007541656494,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 438,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03752699352672437,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1462,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2204887866973877,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 439,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1861,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.3091437816619873,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 440,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 2.605044522279062,
            "feature_preprocessor:kitchen_sinks:n_components": 515
        },
        "cost": 0.0,
        "time": 0.14429306983947754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 441,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003867996955061768,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7572631490137616,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11192199831904337,
            "feature_preprocessor:select_percentile_classification:percentile": 82.09349611651339,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2278517051759263,
        "time": 4.46198296546936,
        "additional_info": {
            "duration": 4.452106952667236,
            "num_run": 442,
            "train_loss": 1.0692024493228773,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 442,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1362216509022134,
        "time": 26.08378791809082,
        "additional_info": {
            "duration": 26.073545932769775,
            "num_run": 443,
            "train_loss": 1.067655377381543,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 443,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0987512461707698,
        "time": 11.08895206451416,
        "additional_info": {
            "duration": 11.079748153686523,
            "num_run": 444,
            "train_loss": 1.0803928711863213,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 444,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015108058898903172,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 368,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.06057607537127998,
            "feature_preprocessor:kitchen_sinks:n_components": 247
        },
        "cost": 0.0,
        "time": 0.23123979568481445,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 445,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.24892256287720507,
            "feature_preprocessor:kitchen_sinks:gamma": 0.28602060363505466,
            "feature_preprocessor:kitchen_sinks:n_components": 62
        },
        "cost": 0.0,
        "time": 0.11528134346008301,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 446,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0021900273637057302,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9079227828843681,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06991997480691332,
            "feature_preprocessor:kitchen_sinks:gamma": 0.045421004984546105,
            "feature_preprocessor:kitchen_sinks:n_components": 8780
        },
        "cost": 0.0,
        "time": 0.1609511375427246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 447,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 520,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00012059981491271997,
            "feature_preprocessor:kitchen_sinks:n_components": 367
        },
        "cost": 0.0,
        "time": 0.2837400436401367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 448,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04140221171398376,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1451,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.019796047690875222,
            "feature_preprocessor:kitchen_sinks:n_components": 65
        },
        "cost": 0.0,
        "time": 0.302138090133667,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 449,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10592526814801279,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.101746085770932,
        "time": 4.5886101722717285,
        "additional_info": {
            "duration": 4.579462766647339,
            "num_run": 450,
            "train_loss": 1.0707125884118756,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 450,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 63.637682848049806,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0948796654852053,
        "time": 2.4574241638183594,
        "additional_info": {
            "duration": 2.448305130004883,
            "num_run": 451,
            "train_loss": 1.0788530873438975,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 451,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1055,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0007898375776691109,
            "feature_preprocessor:kitchen_sinks:n_components": 53
        },
        "cost": 0.0,
        "time": 0.22186899185180664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 452,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010689337267084745,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1393,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.258140802383423,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 453,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1047534213662162,
        "time": 20.342089891433716,
        "additional_info": {
            "duration": 20.333257913589478,
            "num_run": 454,
            "train_loss": 1.0624637641880303,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 454,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 89,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 44.53921093732477,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1408508825295691,
        "time": 2.951848030090332,
        "additional_info": {
            "duration": 2.942843198776245,
            "num_run": 455,
            "train_loss": 1.0710989549219765,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 455,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009946113851720326,
            "feature_preprocessor:kitchen_sinks:gamma": 0.015399436444404203,
            "feature_preprocessor:kitchen_sinks:n_components": 79
        },
        "cost": 0.0,
        "time": 0.14656591415405273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 456,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02159388834071899,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0012458217323798077,
            "feature_preprocessor:kitchen_sinks:n_components": 72
        },
        "cost": 0.0,
        "time": 0.41731715202331543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 457,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1842,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1707139015197754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 458,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010371703925371135,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 472,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2010319232940674,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 459,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009741655203518744,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1222,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2145333290100098,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 460,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023765529644725737,
            "feature_preprocessor:select_percentile_classification:percentile": 35.30805777416859,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0998462154807414,
        "time": 2.398858070373535,
        "additional_info": {
            "duration": 2.3896141052246094,
            "num_run": 461,
            "train_loss": 1.0767958829076303,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 461,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015280126560254416,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0007600469322815932,
            "feature_preprocessor:kitchen_sinks:n_components": 367
        },
        "cost": 0.0,
        "time": 0.14946889877319336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 462,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16263910250455532,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1759,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.293375015258789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 463,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1411,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.3039867877960205,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 464,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 328,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 5.000576768126172e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 4744
        },
        "cost": 0.0,
        "time": 0.2680540084838867,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 465,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2517613963330525,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 438,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.22187959010237915,
            "feature_preprocessor:kitchen_sinks:n_components": 637
        },
        "cost": 0.0,
        "time": 0.24820399284362793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 466,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0019060667608700075,
            "feature_preprocessor:kitchen_sinks:n_components": 277
        },
        "cost": 0.0,
        "time": 0.11599469184875488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 467,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.027943049110266325,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.3552992140281706,
        "time": 10.478174209594727,
        "additional_info": {
            "duration": 10.468338251113892,
            "num_run": 468,
            "train_loss": 1.068611165893428,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 468,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 14.500518919152336,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0889396226987609,
        "time": 2.3576278686523438,
        "additional_info": {
            "duration": 2.348111152648926,
            "num_run": 469,
            "train_loss": 1.0826632682254815,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 469,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 2.788692497525411,
            "feature_preprocessor:kitchen_sinks:n_components": 1878
        },
        "cost": 0.0,
        "time": 0.11575102806091309,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 470,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4184145045178607,
            "feature_preprocessor:kitchen_sinks:gamma": 9.408967269474069e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 317
        },
        "cost": 0.0,
        "time": 0.11827611923217773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 471,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0947735522355992,
        "time": 4.20474100112915,
        "additional_info": {
            "duration": 4.194852113723755,
            "num_run": 472,
            "train_loss": 1.0683001450304175,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 472,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.34066334685820643,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1298349091571744,
        "time": 4.174624919891357,
        "additional_info": {
            "duration": 4.1654579639434814,
            "num_run": 473,
            "train_loss": 1.0710618989801943,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 473,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20296471562272292,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 875,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2195980548858643,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 474,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1611,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.5877051337989743,
            "feature_preprocessor:kitchen_sinks:n_components": 57
        },
        "cost": 0.0,
        "time": 0.2934873104095459,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 475,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1497,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2317728996276855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 476,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23614441525473562,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 386,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.04107996346643718,
            "feature_preprocessor:kitchen_sinks:n_components": 89
        },
        "cost": 0.0,
        "time": 0.22062277793884277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 477,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 27.56254268296445,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1731562701167433,
        "time": 2.4580297470092773,
        "additional_info": {
            "duration": 2.4492359161376953,
            "num_run": 478,
            "train_loss": 1.0721358943683776,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 478,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021983665779550323,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1782,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.276963949203491,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 479,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3158503272060661,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 377,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.135212912018318,
        "time": 4.265380144119263,
        "additional_info": {
            "duration": 4.25563907623291,
            "num_run": 480,
            "train_loss": 1.0689878969979458,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 480,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1700,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1862590312957764,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 481,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004612730443729063,
            "feature_preprocessor:select_percentile_classification:percentile": 47.91462824435737,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2185405602627042,
        "time": 4.58065390586853,
        "additional_info": {
            "duration": 4.571474075317383,
            "num_run": 482,
            "train_loss": 1.0724172704779626,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 482,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011914756238558302,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8575253568207788,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15992693590234605,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0839849075122532,
        "time": 9.984575986862183,
        "additional_info": {
            "duration": 9.975921154022217,
            "num_run": 483,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 483,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15291807325116036,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1151,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2035720348358154,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 484,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00032042223691141795,
            "feature_preprocessor:kitchen_sinks:gamma": 0.8188379519983645,
            "feature_preprocessor:kitchen_sinks:n_components": 344
        },
        "cost": 0.0,
        "time": 0.43321776390075684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 485,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 7.856304168701172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 486,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05299038639794694,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1000,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2475178241729736,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 487,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020886311630568776,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1760,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.002907246688232618,
            "feature_preprocessor:kitchen_sinks:n_components": 741
        },
        "cost": 0.0,
        "time": 0.2724330425262451,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 488,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07058291545747203,
            "feature_preprocessor:select_percentile_classification:percentile": 21.134493893149084,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 1.5544240474700928,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 489,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021968460820534852,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0945445476429263,
        "time": 3.9225778579711914,
        "additional_info": {
            "duration": 3.9135873317718506,
            "num_run": 490,
            "train_loss": 1.081099644917058,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 490,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003343187785528697,
            "feature_preprocessor:kitchen_sinks:gamma": 0.9283913308102073,
            "feature_preprocessor:kitchen_sinks:n_components": 527
        },
        "cost": 0.0,
        "time": 0.12130308151245117,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 491,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2797773165527063,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 931,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.208311080932617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 492,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010059261721763477,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0966057427973706,
        "time": 3.5803420543670654,
        "additional_info": {
            "duration": 3.5713768005371094,
            "num_run": 493,
            "train_loss": 1.0786012328982921,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 493,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.25562293750885445,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 479,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.07911690256427187,
            "feature_preprocessor:kitchen_sinks:n_components": 3502
        },
        "cost": 0.0,
        "time": 0.196397066116333,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 494,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1848998069763184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 495,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.028937894749204197,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1850,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.3109261989593506,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 496,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22850165826452945,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1216,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1958720684051514,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 497,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14151137884239706,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1570,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.1770551204681396,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 498,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 84.92013099094753,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.132751056628314,
        "time": 2.4659299850463867,
        "additional_info": {
            "duration": 2.456955909729004,
            "num_run": 499,
            "train_loss": 1.072127741774279,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 499,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1691,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2285702228546143,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 500,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8733837213954679,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2751845295835331,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0839849075122532,
        "time": 10.16804575920105,
        "additional_info": {
            "duration": 10.158490896224976,
            "num_run": 501,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 501,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012953909932760476,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 114,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0007382180650163268,
            "feature_preprocessor:kitchen_sinks:n_components": 56
        },
        "cost": 0.0,
        "time": 0.21465492248535156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 502,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17692449200690116,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 446,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.5032700175554031,
            "feature_preprocessor:kitchen_sinks:n_components": 973
        },
        "cost": 0.0,
        "time": 0.21269011497497559,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 503,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.29545911286837107,
            "feature_preprocessor:kitchen_sinks:n_components": 7140
        },
        "cost": 0.0,
        "time": 0.13812994956970215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 504,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1742,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.324454722856412,
        "time": 10.298693180084229,
        "additional_info": {
            "duration": 10.290013074874878,
            "num_run": 505,
            "train_loss": 1.0788260360760367,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 505,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011091784350870404,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1527,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.05790073401943077,
            "feature_preprocessor:kitchen_sinks:n_components": 87
        },
        "cost": 0.0,
        "time": 0.3009622097015381,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 506,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1461,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1334628649276197,
        "time": 22.269902229309082,
        "additional_info": {
            "duration": 22.260814905166626,
            "num_run": 507,
            "train_loss": 1.0571260283551704,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 507,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00041662261119636425,
            "feature_preprocessor:kitchen_sinks:gamma": 0.2380958053979165,
            "feature_preprocessor:kitchen_sinks:n_components": 6491
        },
        "cost": 0.0,
        "time": 0.14287590980529785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 508,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1749840442845687,
        "time": 17.419188022613525,
        "additional_info": {
            "duration": 17.41049289703369,
            "num_run": 509,
            "train_loss": 1.072820434534045,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 509,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030836370917666334,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1524,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.8411897668798157,
            "feature_preprocessor:kitchen_sinks:n_components": 87
        },
        "cost": 0.0,
        "time": 0.2737770080566406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 510,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026047679017597376,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1008,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.188654899597168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 511,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00936651006813515,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1908,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2556779384613037,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 512,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3521136021158016,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1643,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.3059821128845215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 513,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 73.1256713403526,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.097977562868052,
        "time": 2.371440887451172,
        "additional_info": {
            "duration": 2.3625802993774414,
            "num_run": 514,
            "train_loss": 1.067574349536473,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 514,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1153282872427286,
        "time": 4.227779150009155,
        "additional_info": {
            "duration": 4.218226909637451,
            "num_run": 515,
            "train_loss": 1.0679418173728117,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 515,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010061449825954913,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1742,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.173995270138558e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 3876
        },
        "cost": 0.0,
        "time": 0.2795238494873047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 516,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.8433137494767791,
            "feature_preprocessor:kitchen_sinks:n_components": 3703
        },
        "cost": 0.0,
        "time": 0.12242507934570312,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 517,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1403,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.22633695602417,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 518,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001836988615495966,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1751,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00031894013688691205,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.30680227279663086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 519,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.381121418395012,
            "feature_preprocessor:kitchen_sinks:gamma": 7.122227229242726,
            "feature_preprocessor:kitchen_sinks:n_components": 83
        },
        "cost": 0.0,
        "time": 0.1463947296142578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 520,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 7.357910007691324e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 1842
        },
        "cost": 0.0,
        "time": 0.14422869682312012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 521,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7207370227040414,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22833179627209366,
            "feature_preprocessor:select_percentile_classification:percentile": 37.91718861477474,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1608935894558245,
        "time": 2.5553760528564453,
        "additional_info": {
            "duration": 2.546833038330078,
            "num_run": 522,
            "train_loss": 1.066189705422683,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 522,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3301031502231085,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1592,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2239480018615723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 523,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1364,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1351306384516886,
        "time": 4.369270086288452,
        "additional_info": {
            "duration": 4.3589770793914795,
            "num_run": 524,
            "train_loss": 1.0724952096106177,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 524,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003475208847926447,
            "feature_preprocessor:select_percentile_classification:percentile": 21.176021022167006,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1270717286303322,
        "time": 4.276746034622192,
        "additional_info": {
            "duration": 4.268020153045654,
            "num_run": 525,
            "train_loss": 1.0563530491560766,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 525,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038906023431876935,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8287965498532017,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24736276121431394,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1742179536619048,
        "time": 21.355035066604614,
        "additional_info": {
            "duration": 21.346399784088135,
            "num_run": 526,
            "train_loss": 1.1683344626483656,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 526,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0182377200702881,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1568,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2680068016052246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 527,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009089063347625556,
            "feature_preprocessor:select_percentile_classification:percentile": 88.39076682348836,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0839849075122532,
        "time": 2.4178590774536133,
        "additional_info": {
            "duration": 2.409029006958008,
            "num_run": 528,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 528,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1056630611419678,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 529,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22226320775953592,
            "feature_preprocessor:select_percentile_classification:percentile": 23.28695665302737,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0958383869449213,
        "time": 2.79780912399292,
        "additional_info": {
            "duration": 2.7889740467071533,
            "num_run": 530,
            "train_loss": 1.0588703598486047,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 530,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026931775747308095,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0032041352120477282,
            "feature_preprocessor:kitchen_sinks:n_components": 202
        },
        "cost": 0.0,
        "time": 0.13588190078735352,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 531,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013038441708580996,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1934,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.203244209289551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 532,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1935,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2649331092834473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 533,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006973761704040392,
            "feature_preprocessor:select_percentile_classification:percentile": 13.08755634327281,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0839849075122532,
        "time": 4.252932071685791,
        "additional_info": {
            "duration": 4.244042158126831,
            "num_run": 534,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 534,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1927,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2554078102111816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 535,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.36252225687609685,
            "feature_preprocessor:kitchen_sinks:gamma": 0.5015952043915249,
            "feature_preprocessor:kitchen_sinks:n_components": 52
        },
        "cost": 0.0,
        "time": 0.14569711685180664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 536,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021229072401620547,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1780,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2295358180999756,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 537,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0221177787826548,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0023918210455049307,
            "feature_preprocessor:kitchen_sinks:n_components": 907
        },
        "cost": 0.0,
        "time": 0.443676233291626,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 538,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1466,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.6779277644686356,
            "feature_preprocessor:kitchen_sinks:n_components": 51
        },
        "cost": 0.0,
        "time": 0.30095791816711426,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 539,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015452665034627958,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8113434529518029,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2888944502979855,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0868804998316768,
        "time": 4.505825042724609,
        "additional_info": {
            "duration": 4.496206045150757,
            "num_run": 540,
            "train_loss": 1.0741246691190607,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 540,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.051845401431124295,
            "feature_preprocessor:kitchen_sinks:n_components": 6945
        },
        "cost": 0.0,
        "time": 0.44083094596862793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 541,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20759790407634415,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0945445476429263,
        "time": 4.015981912612915,
        "additional_info": {
            "duration": 4.006264925003052,
            "num_run": 542,
            "train_loss": 1.081099644917058,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 542,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.092626949992011,
        "time": 4.182458162307739,
        "additional_info": {
            "duration": 4.173460960388184,
            "num_run": 543,
            "train_loss": 1.0680260570197428,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 543,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 93.74323458179218,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1062419990933288,
        "time": 4.2853240966796875,
        "additional_info": {
            "duration": 4.276232957839966,
            "num_run": 544,
            "train_loss": 1.0630209572986666,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 544,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 361,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.128360650771502e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 5825
        },
        "cost": 0.0,
        "time": 0.25405192375183105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 545,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016927233794696638,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1801,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.304225206375122,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 546,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 10,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.221043825149536,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 547,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 32,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1181768098109364,
        "time": 23.032646894454956,
        "additional_info": {
            "duration": 23.023322105407715,
            "num_run": 548,
            "train_loss": 1.067238378533382,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 548,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006972762029029948,
            "feature_preprocessor:kitchen_sinks:n_components": 3870
        },
        "cost": 0.0,
        "time": 0.12055587768554688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 549,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9084739240623926,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11711868592293374,
            "feature_preprocessor:kitchen_sinks:gamma": 0.1758544540631304,
            "feature_preprocessor:kitchen_sinks:n_components": 117
        },
        "cost": 0.0,
        "time": 0.15232324600219727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 550,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016184850951917926,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 594,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 6.042602150558228e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 1023
        },
        "cost": 0.0,
        "time": 0.25741004943847656,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 551,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001971961976486116,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1383,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1140246514980616,
        "time": 23.418709993362427,
        "additional_info": {
            "duration": 23.409350156784058,
            "num_run": 552,
            "train_loss": 1.0660065268415537,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 552,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019124304473251694,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1878,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.198330879211426,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 553,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.26140276889587155,
            "feature_preprocessor:select_percentile_classification:percentile": 96.20138337170263,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1022490840635641,
        "time": 2.5058889389038086,
        "additional_info": {
            "duration": 2.4968011379241943,
            "num_run": 554,
            "train_loss": 1.0607298095059219,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 554,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 4.872020363812144,
            "feature_preprocessor:kitchen_sinks:n_components": 4858
        },
        "cost": 0.0,
        "time": 0.15067028999328613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 555,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03148942342016831,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1628,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0002457806477359269,
            "feature_preprocessor:kitchen_sinks:n_components": 80
        },
        "cost": 0.0,
        "time": 0.2505199909210205,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 556,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009478351023970195,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 414,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 4.783934657863246e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 57
        },
        "cost": 0.0,
        "time": 0.22261786460876465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 557,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017505710937134697,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1692,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.173530101776123,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 558,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03752699352672437,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1462,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2250659465789795,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 559,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022180321263226065,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7584903072723812,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03017784062058967,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0018617299214297826,
            "feature_preprocessor:kitchen_sinks:n_components": 3938
        },
        "cost": 0.0,
        "time": 0.15099787712097168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 560,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015821552203245455,
            "feature_preprocessor:kitchen_sinks:gamma": 5.096129551758539,
            "feature_preprocessor:kitchen_sinks:n_components": 1124
        },
        "cost": 0.0,
        "time": 0.46033501625061035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 561,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.38498411831778645,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1722,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.241901159286499,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 562,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 723,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.007002621278812473,
            "feature_preprocessor:kitchen_sinks:n_components": 5143
        },
        "cost": 0.0,
        "time": 0.26092028617858887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 563,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 24.635148224056667,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1629926833268875,
        "time": 2.8002707958221436,
        "additional_info": {
            "duration": 2.7912771701812744,
            "num_run": 564,
            "train_loss": 1.0736848183895344,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 564,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1112,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 4.4057453667032355e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 721
        },
        "cost": 0.0,
        "time": 0.2359778881072998,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 565,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1000,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 3.925494464839168e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 3150
        },
        "cost": 0.0,
        "time": 0.23424696922302246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 566,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 78.79909283135729,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1008812840430928,
        "time": 4.230400085449219,
        "additional_info": {
            "duration": 4.2213428020477295,
            "num_run": 567,
            "train_loss": 1.0653748525790157,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 567,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10346551279223207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1513,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.191805124282837,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 568,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.050305839053223445,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1325,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.24300217628479,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 569,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1336,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.164146298539688e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 815
        },
        "cost": 0.0,
        "time": 0.2887601852416992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 570,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 94.5216313318233,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1427372652885066,
        "time": 2.899628162384033,
        "additional_info": {
            "duration": 2.8906633853912354,
            "num_run": 571,
            "train_loss": 1.0644558738300205,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 571,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019126794679698442,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1698,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.276794910430908,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 572,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0914466567596337,
        "time": 4.2437357902526855,
        "additional_info": {
            "duration": 4.2346930503845215,
            "num_run": 573,
            "train_loss": 1.0780797360073995,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 573,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 905,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.0534126407781834e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 160
        },
        "cost": 0.0,
        "time": 0.26337313652038574,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 574,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1459,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2263131141662598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 575,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1511,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.06567391115759114,
            "feature_preprocessor:kitchen_sinks:n_components": 176
        },
        "cost": 0.0,
        "time": 0.2481529712677002,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 576,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010689337267084745,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1407,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2415552139282227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 577,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 4.492819470965834e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 4429
        },
        "cost": 0.0,
        "time": 0.14331388473510742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 578,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00449558934673828,
            "feature_preprocessor:select_percentile_classification:percentile": 1.0304225962863682,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0839849075122532,
        "time": 4.454418182373047,
        "additional_info": {
            "duration": 4.445150852203369,
            "num_run": 579,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 579,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 706,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0018288942283254978,
            "feature_preprocessor:kitchen_sinks:n_components": 77
        },
        "cost": 0.0,
        "time": 0.25063300132751465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 580,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17017566598832187,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 23,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 1.4933820095551675,
            "feature_preprocessor:kitchen_sinks:n_components": 191
        },
        "cost": 0.0,
        "time": 0.2533740997314453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 581,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1295,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.244678258895874,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 582,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08284894019473345,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1768,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 95.32926924461393,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.140539518409299,
        "time": 2.679971933364868,
        "additional_info": {
            "duration": 2.6699986457824707,
            "num_run": 583,
            "train_loss": 1.0713400632879184,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 583,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 4.658516748825195,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0695394738593975,
        "time": 2.379513740539551,
        "additional_info": {
            "duration": 2.3707199096679688,
            "num_run": 584,
            "train_loss": 1.069164282707015,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 584,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1578,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 4.696073275227298e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 51
        },
        "cost": 0.0,
        "time": 0.24179291725158691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 585,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 315,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.240586996078491,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 586,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.090292925064281,
        "time": 3.082474946975708,
        "additional_info": {
            "duration": 3.073381185531616,
            "num_run": 587,
            "train_loss": 1.086444668848828,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 587,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 52.35705181357546,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1401078821084907,
        "time": 4.292150974273682,
        "additional_info": {
            "duration": 4.283393144607544,
            "num_run": 588,
            "train_loss": 1.0723886133091713,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 588,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012710013561902671,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0007454089785318983,
            "feature_preprocessor:kitchen_sinks:n_components": 53
        },
        "cost": 0.0,
        "time": 0.46985602378845215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 589,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1815,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.363680124282837,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 590,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011242736490198395,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 594,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.3887795315650205,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.25919413566589355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 591,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08914057761854581,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1656,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1817617416381836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 592,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010580411233648775,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1936,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.255802869796753,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 593,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005490605712690524,
            "feature_preprocessor:select_percentile_classification:percentile": 86.3437795475397,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1382144400943661,
        "time": 2.508960008621216,
        "additional_info": {
            "duration": 2.5000221729278564,
            "num_run": 594,
            "train_loss": 1.072096368030477,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 594,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10787860820571832,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1150,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00011115866539368036,
            "feature_preprocessor:kitchen_sinks:n_components": 73
        },
        "cost": 0.0,
        "time": 0.22583818435668945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 595,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 59.22581323701137,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0948796654852053,
        "time": 2.4800169467926025,
        "additional_info": {
            "duration": 2.471039295196533,
            "num_run": 596,
            "train_loss": 1.0788530873438975,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 596,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15178942703135065,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8412174580747396,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09176371510669719,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0839849075122532,
        "time": 10.023876905441284,
        "additional_info": {
            "duration": 10.014806985855103,
            "num_run": 597,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 597,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0032056707164892146,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7122884397880559,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2651458154773285,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1876340054611658,
        "time": 4.260502099990845,
        "additional_info": {
            "duration": 4.251545190811157,
            "num_run": 598,
            "train_loss": 1.1575648697512395,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 598,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021652543355127417,
            "feature_preprocessor:select_percentile_classification:percentile": 49.784813273414784,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1004177358948994,
        "time": 4.435993194580078,
        "additional_info": {
            "duration": 4.426760911941528,
            "num_run": 599,
            "train_loss": 1.0609882106446953,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 599,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03607109285764406,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9655112116927669,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0777549320768039,
            "feature_preprocessor:select_percentile_classification:percentile": 61.72341793546377,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0866376095069994,
        "time": 2.5872271060943604,
        "additional_info": {
            "duration": 2.5777339935302734,
            "num_run": 600,
            "train_loss": 1.055469643537379,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 600,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03568885806313578,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1706,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.9364412951455486,
            "feature_preprocessor:kitchen_sinks:n_components": 4630
        },
        "cost": 0.0,
        "time": 0.281735897064209,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 601,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019792585359971155,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 856,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 5.253321701807279,
            "feature_preprocessor:kitchen_sinks:n_components": 230
        },
        "cost": 0.0,
        "time": 0.2572479248046875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 602,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010683192454214552,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.779404307434951,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07892663697695523,
            "feature_preprocessor:kitchen_sinks:gamma": 0.001976541855222624,
            "feature_preprocessor:kitchen_sinks:n_components": 663
        },
        "cost": 0.0,
        "time": 0.1892070770263672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 603,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17186289042887723,
            "feature_preprocessor:kitchen_sinks:gamma": 4.816592457294737,
            "feature_preprocessor:kitchen_sinks:n_components": 486
        },
        "cost": 0.0,
        "time": 0.46217799186706543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 604,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00028041321876362004,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1899,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0005551115467312781,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.2534060478210449,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 605,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 64.5247922116959,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1190821238468764,
        "time": 2.7186219692230225,
        "additional_info": {
            "duration": 2.710001230239868,
            "num_run": 606,
            "train_loss": 1.0652187252657472,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 606,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 87.74750157628188,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1046317729252173,
        "time": 4.287553071975708,
        "additional_info": {
            "duration": 4.278435230255127,
            "num_run": 607,
            "train_loss": 1.066776789465637,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 607,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3635459755108702,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1603,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.500303485879251e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 186
        },
        "cost": 0.0,
        "time": 0.29520201683044434,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 608,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02757478155754358,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 286,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.159838914871216,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 609,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15901793715098528,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2402821287548735,
        "time": 3.0445878505706787,
        "additional_info": {
            "duration": 3.0357491970062256,
            "num_run": 610,
            "train_loss": 1.073092793554343,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 610,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1831,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2798850536346436,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 611,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9718450020894187,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19251859996558277,
            "feature_preprocessor:kitchen_sinks:gamma": 1.8794122138208205,
            "feature_preprocessor:kitchen_sinks:n_components": 548
        },
        "cost": 0.0,
        "time": 0.18827509880065918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 612,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.1465730074655058,
        "time": 27.66448998451233,
        "additional_info": {
            "duration": 27.654460906982422,
            "num_run": 613,
            "train_loss": 1.0563020353327701,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 613,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0839849075122532,
        "time": 2.8012242317199707,
        "additional_info": {
            "duration": 2.7924139499664307,
            "num_run": 614,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 614,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 70.85289881649352,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1474238546995312,
        "time": 2.7468109130859375,
        "additional_info": {
            "duration": 2.7377769947052,
            "num_run": 615,
            "train_loss": 1.076037107768953,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 615,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1831,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.290221691131592,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 616,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1977,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2327489852905273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 617,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03332348547513949,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1822,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.232614040374756,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 618,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030406312521730565,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8976870936093646,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.264649551099576,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0005218615576041503,
            "feature_preprocessor:kitchen_sinks:n_components": 2820
        },
        "cost": 0.0,
        "time": 0.19320392608642578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 619,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0028817963786609527,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1302,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 7.617135289476837e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 2581
        },
        "cost": 0.0,
        "time": 0.26049304008483887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 620,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 88.73858490622591,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0834660097484805,
        "time": 2.471139907836914,
        "additional_info": {
            "duration": 2.4620468616485596,
            "num_run": 621,
            "train_loss": 1.087414784510576,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 621,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 63.52678397799415,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.107287827293232,
        "time": 4.426244020462036,
        "additional_info": {
            "duration": 4.417248964309692,
            "num_run": 622,
            "train_loss": 1.0571779066736653,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 622,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1029,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 4.471931246974647e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 6924
        },
        "cost": 0.0,
        "time": 0.2670900821685791,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 623,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00040498322894644544,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0839849075122532,
        "time": 2.747718095779419,
        "additional_info": {
            "duration": 2.737994909286499,
            "num_run": 624,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 624,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1018,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.013001221845946659,
            "feature_preprocessor:kitchen_sinks:n_components": 54
        },
        "cost": 0.0,
        "time": 0.2662851810455322,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 625,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02657007807059322,
            "feature_preprocessor:select_percentile_classification:percentile": 59.779556063497324,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.128721961580442,
        "time": 4.317061185836792,
        "additional_info": {
            "duration": 4.308020830154419,
            "num_run": 626,
            "train_loss": 1.0650891539934892,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 626,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0058751119314950796,
            "feature_preprocessor:kitchen_sinks:n_components": 193
        },
        "cost": 0.0,
        "time": 0.17238903045654297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 627,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 4.733587653779418,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.072924682417243,
        "time": 4.1827943325042725,
        "additional_info": {
            "duration": 4.173838138580322,
            "num_run": 628,
            "train_loss": 1.0732139660536102,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 628,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0003953340830964303,
            "feature_preprocessor:kitchen_sinks:n_components": 7468
        },
        "cost": 0.0,
        "time": 0.17107200622558594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 629,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007254502958100763,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 423,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1258339881896973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 630,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.24839548881151818,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 311,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.36019950891524427,
            "feature_preprocessor:kitchen_sinks:n_components": 271
        },
        "cost": 0.0,
        "time": 0.24634408950805664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 631,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1648,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.294959783554077,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 632,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11181428601477762,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00019621378213614826,
            "feature_preprocessor:kitchen_sinks:n_components": 849
        },
        "cost": 0.0,
        "time": 0.17438793182373047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 633,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008675676301400105,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 212,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 5.73709912166756e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.2490251064300537,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 634,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019493345380110653,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 349,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 68.8918142360982,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1448191345394245,
        "time": 2.671998977661133,
        "additional_info": {
            "duration": 2.6622121334075928,
            "num_run": 635,
            "train_loss": 1.0702989244550218,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 635,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1929,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.295027017593384,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 636,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01377386733949251,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 988,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.0534126407781834e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 243
        },
        "cost": 0.0,
        "time": 0.26717495918273926,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 637,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007925552218277272,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1605,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0001557262263736008,
            "feature_preprocessor:kitchen_sinks:n_components": 51
        },
        "cost": 0.0,
        "time": 0.2605581283569336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 638,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.12609373953287,
        "time": 4.555073976516724,
        "additional_info": {
            "duration": 4.546288728713989,
            "num_run": 639,
            "train_loss": 1.064834952241211,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 639,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22012985744922794,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 819,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006447512220702297,
            "feature_preprocessor:kitchen_sinks:n_components": 9480
        },
        "cost": 0.0,
        "time": 0.26613402366638184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 640,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.435326991422808,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9022288635046488,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2653782690589908,
            "feature_preprocessor:kitchen_sinks:gamma": 0.09143231513862785,
            "feature_preprocessor:kitchen_sinks:n_components": 2554
        },
        "cost": 0.0,
        "time": 0.16158366203308105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 641,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008914677347378265,
            "feature_preprocessor:select_percentile_classification:percentile": 34.167729844082174,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0948139957818912,
        "time": 4.2609028816223145,
        "additional_info": {
            "duration": 4.2517218589782715,
            "num_run": 642,
            "train_loss": 1.08157593327207,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 642,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2148187511923621,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1667,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2824251651763916,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 643,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.0168930107187415,
            "feature_preprocessor:kitchen_sinks:n_components": 161
        },
        "cost": 0.0,
        "time": 0.16611504554748535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 644,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004493862161213255,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 106,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2245981693267822,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 645,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07316918881918277,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1793,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.199306011199951,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 646,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 26.354965327713675,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0839849075122532,
        "time": 2.4008100032806396,
        "additional_info": {
            "duration": 2.391533851623535,
            "num_run": 647,
            "train_loss": 1.0839875121583398,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 647,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 21.158145542964654,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1213316207850963,
        "time": 2.3010940551757812,
        "additional_info": {
            "duration": 2.292044162750244,
            "num_run": 648,
            "train_loss": 1.056465327655503,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 648,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004220470128762887,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 905,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.0534126407781834e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 131
        },
        "cost": 0.0,
        "time": 0.23671507835388184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 649,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11146115422163688,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1768,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.2425988604021249,
            "feature_preprocessor:kitchen_sinks:n_components": 178
        },
        "cost": 0.0,
        "time": 0.27971816062927246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 650,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0728403495710677,
        "time": 23.56476902961731,
        "additional_info": {
            "duration": 23.55435276031494,
            "num_run": 651,
            "train_loss": 1.0763126785911121,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 651,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1814,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 80.39649372470176,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.142616020619305,
        "time": 3.1006569862365723,
        "additional_info": {
            "duration": 3.09043288230896,
            "num_run": 652,
            "train_loss": 1.069208254610303,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 652,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014935298943458992,
            "feature_preprocessor:kitchen_sinks:gamma": 0.000839436394826538,
            "feature_preprocessor:kitchen_sinks:n_components": 84
        },
        "cost": 0.0,
        "time": 0.13925814628601074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 653,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 234,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 5.6590488789389496e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.2777540683746338,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 654,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1625,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1960761547088623,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 655,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.34216381222044634,
            "feature_preprocessor:kitchen_sinks:gamma": 0.013785114837499082,
            "feature_preprocessor:kitchen_sinks:n_components": 8476
        },
        "cost": 0.0,
        "time": 0.12314009666442871,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 656,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 878,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00010485912518897782,
            "feature_preprocessor:kitchen_sinks:n_components": 1979
        },
        "cost": 0.0,
        "time": 0.24924302101135254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 657,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005714611435004279,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1938,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0001886830289737635,
            "feature_preprocessor:kitchen_sinks:n_components": 1823
        },
        "cost": 0.0,
        "time": 0.2469770908355713,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 658,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.023729238117816714,
            "feature_preprocessor:kitchen_sinks:n_components": 367
        },
        "cost": 0.0,
        "time": 0.1715867519378662,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 659,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1822,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.2054388523101807,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 660,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.056363067829832844,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0928242550797924,
        "time": 4.075612783432007,
        "additional_info": {
            "duration": 4.066857099533081,
            "num_run": 661,
            "train_loss": 1.0669981346626285,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 661,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1000,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.005039385269575103,
            "feature_preprocessor:kitchen_sinks:n_components": 62
        },
        "cost": 0.0,
        "time": 0.2332310676574707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 662,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025640486866939233,
            "feature_preprocessor:kitchen_sinks:gamma": 0.4491098168252118,
            "feature_preprocessor:kitchen_sinks:n_components": 739
        },
        "cost": 0.0,
        "time": 0.14411091804504395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 663,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00016852364828962084,
            "feature_preprocessor:kitchen_sinks:n_components": 259
        },
        "cost": 0.0,
        "time": 0.13925814628601074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 664,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006053923298938814,
            "feature_preprocessor:kitchen_sinks:n_components": 4763
        },
        "cost": 0.0,
        "time": 0.1499190330505371,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 665,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 43.023637096699126,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0981377154490624,
        "time": 2.3958709239959717,
        "additional_info": {
            "duration": 2.3869130611419678,
            "num_run": 666,
            "train_loss": 1.058383325413929,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 666,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016388965495827874,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8034948574048091,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.016618430745729086,
            "feature_preprocessor:select_percentile_classification:percentile": 19.53804263404269,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.177556069680916,
        "time": 2.4722418785095215,
        "additional_info": {
            "duration": 2.4629058837890625,
            "num_run": 667,
            "train_loss": 1.0612044919600032,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 667,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0980064894161454,
        "time": 12.929601907730103,
        "additional_info": {
            "duration": 12.920051097869873,
            "num_run": 668,
            "train_loss": 1.0806008768180846,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 668,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2396512068510508,
            "feature_preprocessor:select_percentile_classification:percentile": 74.03143886236153,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1572255892683463,
        "time": 2.3723866939544678,
        "additional_info": {
            "duration": 2.3632099628448486,
            "num_run": 669,
            "train_loss": 1.0858473310839951,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 669,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005419542346011773,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1279,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.164146298539688e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 815
        },
        "cost": 0.0,
        "time": 0.2719600200653076,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 670,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002314723104436226,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9549732443377614,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18306245375914726,
            "feature_preprocessor:kitchen_sinks:gamma": 0.05320893383065972,
            "feature_preprocessor:kitchen_sinks:n_components": 599
        },
        "cost": 0.0,
        "time": 0.16176986694335938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 671,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.0859413271140097,
        "time": 10.991119861602783,
        "additional_info": {
            "duration": 10.98197889328003,
            "num_run": 672,
            "train_loss": 1.083731581415685,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 672,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007022921305846223,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 445,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 5.219379965720755e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.25900721549987793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 673,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022110659133900876,
            "feature_preprocessor:select_percentile_classification:percentile": 14.747798542542577,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1694666242726355,
        "time": 4.516496896743774,
        "additional_info": {
            "duration": 4.507475852966309,
            "num_run": 674,
            "train_loss": 1.0605257570817619,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 674,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03479365599402302,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.0976258760119693,
        "time": 4.127954006195068,
        "additional_info": {
            "duration": 4.118839740753174,
            "num_run": 675,
            "train_loss": 1.0665770595174182,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 675,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004345835995422955,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1261,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 58.13744371315469,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1307798243462996,
        "time": 4.538763761520386,
        "additional_info": {
            "duration": 4.529350757598877,
            "num_run": 676,
            "train_loss": 1.0615289754776882,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 676,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3180542093261843,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1303,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.3246459520431923,
            "feature_preprocessor:kitchen_sinks:n_components": 950
        },
        "cost": 0.0,
        "time": 0.2406008243560791,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 677,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016927233794696638,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1935,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.265216112136841,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 678,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 6.723233926627,
            "feature_preprocessor:kitchen_sinks:n_components": 168
        },
        "cost": 0.0,
        "time": 0.14473485946655273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 679,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4274468513005768,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1343,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 2.799585033149308,
            "feature_preprocessor:kitchen_sinks:n_components": 185
        },
        "cost": 0.0,
        "time": 0.266693115234375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 680,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010163648988781413,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00018508933925702822,
            "feature_preprocessor:kitchen_sinks:n_components": 1303
        },
        "cost": 0.0,
        "time": 0.17449283599853516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 681,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 62.03214350103271,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.103472731799963,
        "time": 2.4810009002685547,
        "additional_info": {
            "duration": 2.472003698348999,
            "num_run": 682,
            "train_loss": 1.0662037863936538,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 682,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.228314563551634,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8685360327889224,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16988383072329602,
            "feature_preprocessor:select_percentile_classification:percentile": 34.059617497925366,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.095463339916336,
        "time": 2.5451440811157227,
        "additional_info": {
            "duration": 2.536013126373291,
            "num_run": 683,
            "train_loss": 1.068843134080637,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 683,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007774001756749266,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.168281164722434,
        "time": 3.667391061782837,
        "additional_info": {
            "duration": 3.658431053161621,
            "num_run": 684,
            "train_loss": 1.0696838015595729,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 684,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1697,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.1706838607788086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 685,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00917646578266295,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1606,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.195145845413208,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 686,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0043461692637650805,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1030,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.186735153198242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 687,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 77.98857788928515,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1279194688260792,
        "time": 4.334237098693848,
        "additional_info": {
            "duration": 4.32497501373291,
            "num_run": 688,
            "train_loss": 1.0676263509444135,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 688,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.38033653241264903,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 904,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.2530417442321777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 689,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010113606287458467,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1983,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.276826858520508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 690,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.467734003863185,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1027,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0018464388076022027,
            "feature_preprocessor:kitchen_sinks:n_components": 63
        },
        "cost": 0.0,
        "time": 0.2621476650238037,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 691,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03143079736608275,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1963,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 0.0,
        "time": 2.208728075027466,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 692,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 816,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0032680131977894026,
            "feature_preprocessor:kitchen_sinks:n_components": 7068
        },
        "cost": 0.0,
        "time": 0.2561650276184082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 693,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 7.45115847742177e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 1996
        },
        "cost": 0.0,
        "time": 0.17330288887023926,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 694,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 64.36666258512645,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1505054586018306,
        "time": 2.7835519313812256,
        "additional_info": {
            "duration": 2.7745749950408936,
            "num_run": 695,
            "train_loss": 1.0760684815127552,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 695,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004155170398903339,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1875,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 2.215320110321045,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 613, in fit_predict_and_loss\n    optimization_loss = self._loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 344, in _loss\n    return calculate_loss(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 484, in calculate_loss\n    score = calculate_score(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 449, in calculate_score\n    return _compute_scorer(metric, prediction, solution, task_type)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 573, in _compute_scorer\n    score = metric(solution, prediction)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/metrics/__init__.py\", line 104, in __call__\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_lrg_EOD_sex.py\", line 324, in accuracy\n    disparate_impact(subset_data_orig_train, prediction, protected_attr),\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/upgrade/metric.py\", line 27, in disparate_impact\n    math.log(\nValueError: math domain error\n",
            "error": "ValueError('math domain error')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 696,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08841986608965091,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 302,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 6.11543326840791e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 2185
        },
        "cost": 0.0,
        "time": 0.24580788612365723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 697,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 98.11476342146118,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1074833137852127,
        "time": 2.4643149375915527,
        "additional_info": {
            "duration": 2.454954147338867,
            "num_run": 698,
            "train_loss": 1.0650949592809151,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 698,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01734825670921214,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1862,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.021298061081660012,
            "feature_preprocessor:kitchen_sinks:n_components": 81
        },
        "cost": 0.0,
        "time": 0.3080871105194092,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 699,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011082387961976355,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 246,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 7.087674469462431,
            "feature_preprocessor:kitchen_sinks:n_components": 2552
        },
        "cost": 0.0,
        "time": 0.24945807456970215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 700,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 942,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 3.0534126407781834e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 115
        },
        "cost": 0.0,
        "time": 0.2326042652130127,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 701,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17620821770536563,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1497,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.1365126201732971,
        "time": 4.3851447105407715,
        "additional_info": {
            "duration": 4.375068187713623,
            "num_run": 702,
            "train_loss": 1.0745353674529454,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 702,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0009537443923826974,
            "feature_preprocessor:kitchen_sinks:n_components": 988
        },
        "cost": 0.0,
        "time": 0.12320804595947266,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 703,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007671042241318562,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2358936942516456,
        "time": 10.940459966659546,
        "additional_info": {
            "duration": 10.931183099746704,
            "num_run": 704,
            "train_loss": 1.0708520412686087,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 704,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 84.99133324464545,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.102437065250987,
        "time": 4.317148923873901,
        "additional_info": {
            "duration": 4.307887077331543,
            "num_run": 705,
            "train_loss": 1.0800527007967353,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 705,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11016358798271367,
            "feature_preprocessor:kitchen_sinks:gamma": 0.011718927707759275,
            "feature_preprocessor:kitchen_sinks:n_components": 3866
        },
        "cost": 0.0,
        "time": 0.16257905960083008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 706,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0976828140215113,
            "feature_preprocessor:kitchen_sinks:n_components": 1854
        },
        "cost": 0.0,
        "time": 0.44096875190734863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 707,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 264,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 4.783934657863246e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 57
        },
        "cost": 0.0,
        "time": 0.24837517738342285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 708,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 35.81780926563315,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0732117338523226,
        "time": 2.4027459621429443,
        "additional_info": {
            "duration": 2.3939566612243652,
            "num_run": 709,
            "train_loss": 1.0598917355125508,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 709,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020133558735801446,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.102437065250987,
        "time": 3.236384153366089,
        "additional_info": {
            "duration": 3.227388858795166,
            "num_run": 710,
            "train_loss": 1.0800213270529333,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 710,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7119524593140266,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29092841958436694,
            "feature_preprocessor:kitchen_sinks:gamma": 3.5166111108098906e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 190
        },
        "cost": 0.0,
        "time": 0.13390588760375977,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 711,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018907871927219006,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 0.0,
        "time": 5.0046069622039795,
        "additional_info": {
            "error": "Timeout",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 712,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1130,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 6.240496842029776e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 51
        },
        "cost": 0.0,
        "time": 0.0,
        "additional_info": {}
    }
]