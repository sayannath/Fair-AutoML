[
    {
        "config_id": 1,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.25608,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.5,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 250,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 100,
            "feature_preprocessor:nystroem_sampler:gamma": 0.1
        },
        "cost": 0.0,
        "time": 0.18709087371826172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Default"
        }
    },
    {
        "config_id": 2,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6396271275072221,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.8171197098537293,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 517,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005459604392421436,
            "feature_preprocessor:select_percentile_classification:percentile": 21.813580056891706,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0612234608689526,
        "time": 8.985690832138062,
        "additional_info": {
            "duration": 8.970907211303711,
            "num_run": 3,
            "train_loss": 1.0168710874003568,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 3,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.26201448291149293,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.40969413750975786,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 427,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03779286795775615,
            "feature_preprocessor:select_rates_classification:alpha": 0.05028368524898114,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.5626780986785889,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 4,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.7391509603549309,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.3182272550910716,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 586,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026743602284517602,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 846,
            "feature_preprocessor:nystroem_sampler:coef0": 0.18315300200456308,
            "feature_preprocessor:nystroem_sampler:gamma": 0.002116900060613903
        },
        "cost": 0.0,
        "time": 3.620666980743408,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 5,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.3304353003505261,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.5817771307823225,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 12,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 531,
            "feature_preprocessor:select_rates_classification:alpha": 0.0217753616287089,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.0393540934418706,
        "time": 5.201949834823608,
        "additional_info": {
            "duration": 5.188222885131836,
            "num_run": 6,
            "train_loss": 1.0076381235243854,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 6,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.4113196202438669,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.5630141673483646,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 12,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 280,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01070215535922035,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 3501,
            "feature_preprocessor:nystroem_sampler:coef0": 0.2675349648141756,
            "feature_preprocessor:nystroem_sampler:degree": 4,
            "feature_preprocessor:nystroem_sampler:gamma": 1.9183162960106208
        },
        "cost": 0.0,
        "time": 49.47057509422302,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 7,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.4218823918891089,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.423994875362489,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 733,
            "feature_preprocessor:select_rates_classification:alpha": 0.2293403487694914,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1609179973602295,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 8,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.33857472487162527,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.5008408137088132,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 277,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0378687314380284,
            "feature_preprocessor:select_percentile_classification:percentile": 62.09975078373219,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.15440702438354492,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 9,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.5430682011624647,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.4898299598593201,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 493,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8367363178578703,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16904358048351203,
            "feature_preprocessor:select_percentile_classification:percentile": 53.317862544055856,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0370023818146428,
        "time": 4.8265910148620605,
        "additional_info": {
            "duration": 4.8127710819244385,
            "num_run": 10,
            "train_loss": 1.010587411719064,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 10,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.3833506582858321,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.2708485083578467,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 735,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3377006228452489,
            "feature_preprocessor:select_rates_classification:alpha": 0.37173637235290014,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.018020296749852,
        "time": 8.62069320678711,
        "additional_info": {
            "duration": 8.604767799377441,
            "num_run": 11,
            "train_loss": 1.019282416705042,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 11,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.7700087406267281,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.8172442397382141,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 12,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 271,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.24404621037276927,
            "feature_preprocessor:select_percentile_classification:percentile": 55.69139829310432,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.42087769508361816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 12,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.44836594120838663,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.5635468436571336,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 264,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000724552110468072,
            "feature_preprocessor:select_rates_classification:alpha": 0.16284231584040543,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12756609916687012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 13,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.43474400427325843,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.2504968721479175,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 9,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 290,
            "feature_preprocessor:select_percentile_classification:percentile": 65.77354740509455,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0404620621603542,
        "time": 3.57491397857666,
        "additional_info": {
            "duration": 3.562598943710327,
            "num_run": 14,
            "train_loss": 1.01930490208117,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 14,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.29464505823072584,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.2770583722441938,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 709,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004051734698704584,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 880,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 208
        },
        "cost": 0.0,
        "time": 0.392179012298584,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 15,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.56957285263138,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.7993561140612736,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 12,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 406,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13394487790685428,
            "feature_preprocessor:select_rates_classification:alpha": 0.2722050271919485,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.18504905700683594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 16,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.3684678303117337,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.4610277748733209,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 268,
            "feature_preprocessor:select_rates_classification:alpha": 0.20069350549286702,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.0609456918681381,
        "time": 5.88778281211853,
        "additional_info": {
            "duration": 5.876466274261475,
            "num_run": 17,
            "train_loss": 1.0102156986238167,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 17,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.49639055563973183,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.5534984001506437,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 254,
            "feature_preprocessor:select_rates_classification:alpha": 0.3884255678927477,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.22701072692871094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 18,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.3420851498793903,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.25173544900560846,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 481,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 3825,
            "feature_preprocessor:nystroem_sampler:coef0": 0.07667725326777575,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 0.23057769634764883
        },
        "cost": 0.0,
        "time": 52.63926410675049,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 19,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.5356538040085035,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.5695416623866185,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 9,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 304,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.932028300913104,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2287565520963107,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 576,
            "feature_preprocessor:nystroem_sampler:coef0": -0.9904760765028746,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0011323101872907475
        },
        "cost": 1.0547234426511545,
        "time": 63.60278010368347,
        "additional_info": {
            "duration": 63.591256856918335,
            "num_run": 20,
            "train_loss": 1.0158776136166114,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 20,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.268624776850673,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.6547972632277875,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 716,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1444,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.011354015885930747,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.043354907457596,
        "time": 5.91644811630249,
        "additional_info": {
            "duration": 5.901557922363281,
            "num_run": 21,
            "train_loss": 1.0194196274615623,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 21,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.7011438287794076,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.3657207295831489,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 418,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 480
        },
        "cost": 1.0485042084382012,
        "time": 33.23305702209473,
        "additional_info": {
            "duration": 33.22065997123718,
            "num_run": 22,
            "train_loss": 1.024916062457459,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 22,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.6407541765580824,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.733899624279669,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 719,
            "feature_preprocessor:select_rates_classification:alpha": 0.17996987095874595,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.16858601570129395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 23,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.3303502504694944,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.457797989975985,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 487,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1099,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.3717134279644795,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 2.0629422664642334,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 24,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.3790317701673271,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.7714991626533804,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 737,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006984156528889393,
            "feature_preprocessor:select_rates_classification:alpha": 0.4462995394303435,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 1.997652292251587,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 25,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.48058040331762225,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.567002149699784,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 723,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00051976943616499,
            "feature_preprocessor:select_percentile_classification:percentile": 6.690995888400301,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0691755514792585,
        "time": 5.055264234542847,
        "additional_info": {
            "duration": 5.0400238037109375,
            "num_run": 26,
            "train_loss": 1.0477310840727654,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 26,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.4897523391404204,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.2892014082620519,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 608,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 196,
            "feature_preprocessor:nystroem_sampler:coef0": 0.7269188646694398,
            "feature_preprocessor:nystroem_sampler:gamma": 0.2704647283957166
        },
        "cost": 0.0,
        "time": 0.5320901870727539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 27,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.5707909718204374,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.3458495932636599,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 252,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009797177027127564,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7806490329420978,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1866847133549843,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 94,
            "feature_preprocessor:nystroem_sampler:gamma": 8.779455547603212e-05
        },
        "cost": 0.0,
        "time": 0.19765210151672363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 28,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6961680826017698,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.6962774617296156,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 730,
            "feature_preprocessor:select_percentile_classification:percentile": 95.62636841103253,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.17435383796691895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 29,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.4131170806821651,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.7418963773497931,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 359,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1855,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.48559795066834865,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.0413561078728066,
        "time": 4.913538932800293,
        "additional_info": {
            "duration": 4.90203595161438,
            "num_run": 30,
            "train_loss": 1.0413573904606872,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 30,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.7753313645764505,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.6227067507402012,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 578,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007697734513183403,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 1155,
            "feature_preprocessor:nystroem_sampler:coef0": -0.988037584291444,
            "feature_preprocessor:nystroem_sampler:gamma": 1.0767701904859384
        },
        "cost": 0.0,
        "time": 5.240252256393433,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 31,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.44066439577940686,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.2687408374761784,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 285,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015246748520132561,
            "feature_preprocessor:select_percentile_classification:percentile": 15.646471867078864,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.048173821259928,
        "time": 3.1122419834136963,
        "additional_info": {
            "duration": 3.1002590656280518,
            "num_run": 32,
            "train_loss": 1.0273184310513455,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 32,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.39406346698695716,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.6435261983651537,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 591,
            "feature_preprocessor:select_percentile_classification:percentile": 46.426276216112655,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.14029383659362793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 33,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.7216562676887388,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.7343985307266743,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 405,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00032279665082555857,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 387,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.16852651244075326,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.0537526855335813,
        "time": 4.7044501304626465,
        "additional_info": {
            "duration": 4.692201137542725,
            "num_run": 34,
            "train_loss": 1.0537543525797943,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 34,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.47830251886346686,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.4220597499357767,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 291,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.034972948198151006,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.708402854727777,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.14004609828117712,
            "feature_preprocessor:select_percentile_classification:percentile": 88.54158415464998,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 1.9907000064849854,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 35,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.3020998821814133,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.254047333304339,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 694,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00024168409229198288,
            "feature_preprocessor:select_percentile_classification:percentile": 4.91830312974138,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.4534921646118164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 36,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.6225529659432449,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.5100638780558086,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 405,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3361033360199985,
            "feature_preprocessor:select_rates_classification:alpha": 0.2323560639143408,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 2.0333008766174316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 37,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.673615362609918,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.5248684471989601,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 625,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026622364935960856,
            "feature_preprocessor:select_percentile_classification:percentile": 98.40000185159408,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 2.0211522579193115,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 38,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.7664347722035164,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.6187541166953676,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 12,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 307,
            "feature_preprocessor:select_rates_classification:alpha": 0.11519564352763983,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1649460792541504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 39,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6898040085099034,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.36932664650976477,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 525,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19864672221426172,
            "feature_preprocessor:select_percentile_classification:percentile": 86.29445013131489,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 1.9731225967407227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 40,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.759521493390917,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.6960947925776293,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 555,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06732257644954316,
            "feature_preprocessor:select_percentile_classification:percentile": 48.71625509982415,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 2.0248639583587646,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 41,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.4903226017718354,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.8026469437910325,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 341,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001889452977516688,
            "feature_preprocessor:select_rates_classification:alpha": 0.28592154890721716,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.4669790267944336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 42,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.3289543571550158,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.6359076720781411,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 299,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7796566764187295,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08549453700967537,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 257,
            "feature_preprocessor:nystroem_sampler:gamma": 4.805355608942815e-05
        },
        "cost": 0.0,
        "time": 0.32119083404541016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 43,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.5617535274645207,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.3014375741263976,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 455,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 196,
            "feature_preprocessor:nystroem_sampler:coef0": 0.42798754628753777,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 0.9428199713516994
        },
        "cost": 0.0,
        "time": 0.313215970993042,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 44,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.4400574565723935,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.5213863918525706,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 738,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07237931524654662,
            "feature_preprocessor:select_rates_classification:alpha": 0.3054708624346116,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 2.033231019973755,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 45,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.5615022452543716,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.2706861142294776,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 372,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003341132582834784,
            "feature_preprocessor:select_percentile_classification:percentile": 71.81930354438829,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.12794280052185059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 46,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.4225514098044979,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.5237980539139313,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 513,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013426225191022466,
            "feature_preprocessor:select_percentile_classification:percentile": 14.730112096755198,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.1839599609375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 47,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.3352893968004421,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.23593699912792768,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 657,
            "feature_preprocessor:select_rates_classification:alpha": 0.27741558395886573,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.064614567073931,
        "time": 4.326709985733032,
        "additional_info": {
            "duration": 4.310847043991089,
            "num_run": 48,
            "train_loss": 1.032635473909174,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 48,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.3503227540412719,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.3920307734772562,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 505,
            "feature_preprocessor:select_percentile_classification:percentile": 92.99325624682639,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.4738011360168457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 49,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.30201396759938637,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.264633889901288,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 12,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 443,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011649966554805276,
            "feature_preprocessor:select_rates_classification:alpha": 0.30618844315761695,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.4822568893432617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 50,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.4904067855958547,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.4709723910590087,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 730,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12619893682050676,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1922,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 10.96961233097015,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0511500731324461,
        "time": 8.192943096160889,
        "additional_info": {
            "duration": 8.173583984375,
            "num_run": 51,
            "train_loss": 1.0468971372285532,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 51,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.5039861721070332,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.6117894153679674,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 480,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012566961281863537,
            "feature_preprocessor:select_percentile_classification:percentile": 25.31215531665251,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0619691102069635,
        "time": 10.535269260406494,
        "additional_info": {
            "duration": 10.520867824554443,
            "num_run": 52,
            "train_loss": 1.0158591942173716,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 52,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.5549565360982185,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.7972792186776829,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 627,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22113628644214803,
            "feature_preprocessor:select_percentile_classification:percentile": 48.660786638937964,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.1518096923828125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 53,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.46999789898863337,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.31223795613367433,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 332,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 675,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 16.619200161374728,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0641177713283712,
        "time": 3.6395280361175537,
        "additional_info": {
            "duration": 3.626420021057129,
            "num_run": 54,
            "train_loss": 1.0562411026369036,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 54,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.7784089792366861,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.38787134454857386,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 664,
            "feature_preprocessor:select_rates_classification:alpha": 0.03417745452677383,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.0641829538603451,
        "time": 3.6508920192718506,
        "additional_info": {
            "duration": 3.6358630657196045,
            "num_run": 55,
            "train_loss": 1.0432779786651762,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 55,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6480282287947274,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.7227196444363833,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 468,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8954784245780969,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07908503102324793,
            "feature_preprocessor:select_percentile_classification:percentile": 8.834221978215991,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0532431010769585,
        "time": 3.9021260738372803,
        "additional_info": {
            "duration": 3.8897080421447754,
            "num_run": 56,
            "train_loss": 1.0439558613453597,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 56,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.5913259905137924,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.44848192398315373,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 405,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15545656653835271,
            "feature_preprocessor:select_rates_classification:alpha": 0.22860015708581377,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.055043643621881,
        "time": 3.965162992477417,
        "additional_info": {
            "duration": 3.9521470069885254,
            "num_run": 57,
            "train_loss": 1.0383391950826417,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 57,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.4617283164892762,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.8249039162695692,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 642,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8329062786906444,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2764152592063749,
            "feature_preprocessor:select_percentile_classification:percentile": 7.427454146706213,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.1749410629272461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 58,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.4594261902057496,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.6700630052764376,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 360,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 163,
            "feature_preprocessor:nystroem_sampler:coef0": -0.21440057937389656,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0008443565981017595
        },
        "cost": 1.078674923613055,
        "time": 45.93571734428406,
        "additional_info": {
            "duration": 45.92379403114319,
            "num_run": 59,
            "train_loss": 1.05399518339973,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 59,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6086665797662606,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.42189157529777394,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 10,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 274,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0779427451449748,
            "feature_preprocessor:select_percentile_classification:percentile": 1.4011075848857093,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.16135072708129883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 60,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.7145234538195319,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.3440826280029642,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 10,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 309,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04986656802845975,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1725,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 41.85026426948733,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 2.123443841934204,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 61,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.74493474918751,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.3564550709197416,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 740,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 496
        },
        "cost": 1.0725416509804109,
        "time": 51.07112693786621,
        "additional_info": {
            "duration": 51.0558021068573,
            "num_run": 62,
            "train_loss": 1.000649025446169,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 62,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.37640908619978225,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.2630146805105115,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 503,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1325,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.4180271146683745,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.2718191146850586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 63,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6943377789702505,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.43198141001924945,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 283,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003399360607829863,
            "feature_preprocessor:select_percentile_classification:percentile": 11.316852367607721,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 1.9724700450897217,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 64,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.5861315690037608,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.4009945056590791,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 9,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 284,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 9179,
            "feature_preprocessor:nystroem_sampler:coef0": 0.10027213165855153,
            "feature_preprocessor:nystroem_sampler:gamma": 0.007226194230871644
        },
        "cost": 0.0,
        "time": 279.14087891578674,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 65,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.4754666995718925,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.7508289421831034,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 396,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017273555386075324,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1666,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 87.17823988367803,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0658268380102842,
        "time": 9.278905153274536,
        "additional_info": {
            "duration": 9.266045808792114,
            "num_run": 66,
            "train_loss": 1.0139122344090021,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 66,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.676446594725313,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.25978575669692244,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 696,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019689429586143173,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1492,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.3315746965951965,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.2921929359436035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 67,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.38681061761045377,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.712325559718345,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 626,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01525585801287319,
            "feature_preprocessor:select_rates_classification:alpha": 0.36418818402146685,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 1.972773790359497,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 68,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.7531830008243021,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.5424199176242939,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 534,
            "feature_preprocessor:select_percentile_classification:percentile": 20.545450607786474,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.16880106925964355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 69,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.3016365770199886,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.41280992008394046,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 457,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011704690344180915,
            "feature_preprocessor:select_rates_classification:alpha": 0.3535847625359057,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 2.0004889965057373,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 70,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.5102086417380606,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.7115642434834529,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 12,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 494,
            "feature_preprocessor:select_rates_classification:alpha": 0.4018953151218567,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 1.987896203994751,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 71,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.3836874104194775,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.3878169861778218,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 466,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009434839919302209,
            "feature_preprocessor:select_percentile_classification:percentile": 57.496171507935344,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.2927401065826416,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 72,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.2972200525295046,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.7638675097342943,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 10,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 397,
            "feature_preprocessor:select_rates_classification:alpha": 0.3544222273888792,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1285712718963623,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 73,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.35776128057311485,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.2672459615606115,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 535,
            "feature_preprocessor:select_rates_classification:alpha": 0.16389325319509632,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 2.0146918296813965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 74,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.316555152264006,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.4767100431853484,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 433,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011984247434594524,
            "feature_preprocessor:select_rates_classification:alpha": 0.17051368311252935,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.17395401000976562,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 75,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.5472874084574393,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.41019018525124584,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 671,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1861,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.3435588758573086,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 2.127197027206421,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 76,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.2609517380843336,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.7617510055041162,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 706,
            "feature_preprocessor:select_rates_classification:alpha": 0.24458856464038473,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.0913015751993917,
        "time": 12.637946128845215,
        "additional_info": {
            "duration": 12.621692895889282,
            "num_run": 77,
            "train_loss": 1.05189498309098,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 77,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.7717922595830341,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.7591731459353951,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 566,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21385973864398045,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1329,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 17.947787856257637,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 2.1106040477752686,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 78,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.2805360289457122,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.4891523857140161,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 9,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 720,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002104454192644899,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 519,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 79.1433388642138,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.073125726402693,
        "time": 6.224352836608887,
        "additional_info": {
            "duration": 6.208349227905273,
            "num_run": 79,
            "train_loss": 1.0481883692354563,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 79,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.26065128154237355,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.8103026909475353,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 743,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05389055041541978,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1303,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.24945361771213884,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 2.0827829837799072,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 80,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.7496818889668757,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.766782536753785,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 496,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7215012460914518,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10277585336532655,
            "feature_preprocessor:select_percentile_classification:percentile": 60.28343713108231,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.1388411521911621,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 81,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.594581298763746,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.8194563426744584,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 578,
            "feature_preprocessor:select_percentile_classification:percentile": 33.65239371237939,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 2.002984046936035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 82,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.6368237101644934,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.6142275259483273,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 493,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05410627283975993,
            "feature_preprocessor:select_rates_classification:alpha": 0.01524504989927961,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1281290054321289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 83,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.333463166116663,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.40968711017975656,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 12,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 313,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06237540442774516,
            "feature_preprocessor:select_rates_classification:alpha": 0.28047632658541477,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.0781542312775205,
        "time": 3.08243989944458,
        "additional_info": {
            "duration": 3.07108998298645,
            "num_run": 84,
            "train_loss": 1.060257815976831,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 84,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.3347165308107753,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.3694698710417158,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 451,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012062825137070412,
            "feature_preprocessor:select_percentile_classification:percentile": 13.572780105305437,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.19167494773864746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 85,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.45847382904962125,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.33618604223866916,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 492,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007917540595304131,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.960330066203448,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22736868244831707,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 136,
            "feature_preprocessor:nystroem_sampler:coef0": 0.7394376258809199,
            "feature_preprocessor:nystroem_sampler:degree": 4,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0001939205049038509
        },
        "cost": 1.1017376186349157,
        "time": 28.19991898536682,
        "additional_info": {
            "duration": 28.185964822769165,
            "num_run": 86,
            "train_loss": 1.075633100043488,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 86,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.5854820504608742,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.5799161472259834,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 12,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 368,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02269975398494309,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 398,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 32.89122123430192,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.26064515113830566,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 87,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6785447603035784,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.7569245150740158,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 608,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011362152849934437,
            "feature_preprocessor:select_percentile_classification:percentile": 52.94665216725285,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.45336484909057617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 88,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.41250012364219396,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.45002369596642794,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 411,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013559354030501431,
            "feature_preprocessor:select_percentile_classification:percentile": 88.71486684737161,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 2.002300977706909,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 89,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.28111122918888237,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.3442875738043234,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 737,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 81,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0002822649814463536
        },
        "cost": 0.0,
        "time": 0.22643303871154785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 90,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.7513249848363104,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.784306763598873,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 519,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1012,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 58,
            "feature_preprocessor:nystroem_sampler:gamma": 0.10702368357858225
        },
        "cost": 1.1047383424591983,
        "time": 67.94649696350098,
        "additional_info": {
            "duration": 67.93238592147827,
            "num_run": 91,
            "train_loss": 1.0215803307068687,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 91,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.5613360187170627,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.8116640205631849,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 601,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 51,
            "feature_preprocessor:nystroem_sampler:coef0": 0.9111832159350415,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 0.012737640643739476
        },
        "cost": 0.0,
        "time": 0.1854410171508789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 92,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.5967225566893667,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.4514239410970813,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 649,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017474467233303701,
            "feature_preprocessor:select_rates_classification:alpha": 0.13401441974317196,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12473702430725098,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 93,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.7149792480703558,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.3312867110926828,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 576,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1767,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 48.731020323433754,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0938309421121086,
        "time": 4.588753938674927,
        "additional_info": {
            "duration": 4.574577331542969,
            "num_run": 94,
            "train_loss": 1.057726119060653,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 94,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.5986866761546397,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.33618021476348425,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 286,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9363178063651751,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17640736806767784,
            "feature_preprocessor:select_percentile_classification:percentile": 50.767930220883684,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 2.065117835998535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 95,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.538711687712804,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.6331270491645515,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 345,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 8245
        },
        "cost": 0.0,
        "time": 220.16682887077332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 96,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6396194525190017,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.24767384185033806,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 716,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002506096509972448,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 434,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 69.66398281882952,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0847699368283712,
        "time": 6.139398097991943,
        "additional_info": {
            "duration": 6.123028993606567,
            "num_run": 97,
            "train_loss": 1.0514755379299243,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 97,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.44900886317809496,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.7993623595185964,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 644,
            "feature_preprocessor:select_percentile_classification:percentile": 22.612164480624283,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0899553245193019,
        "time": 7.300141096115112,
        "additional_info": {
            "duration": 7.284759044647217,
            "num_run": 98,
            "train_loss": 1.0666536292527993,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 98,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.4385351837684831,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.8272722147919342,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 501,
            "feature_preprocessor:select_percentile_classification:percentile": 76.0365127716817,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.14644217491149902,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 99,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.35719919861030797,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.295946249294592,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 9,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 288,
            "feature_preprocessor:select_percentile_classification:percentile": 79.98555177752303,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.0908383436887383,
        "time": 2.759967088699341,
        "additional_info": {
            "duration": 2.7489171028137207,
            "num_run": 100,
            "train_loss": 1.0699477531922195,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 100,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6937656582952993,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.7632225243037184,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 389,
            "feature_preprocessor:select_percentile_classification:percentile": 82.36184613220145,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.089991257758291,
        "time": 5.903209924697876,
        "additional_info": {
            "duration": 5.890866994857788,
            "num_run": 101,
            "train_loss": 1.0539120250614373,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 101,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.6562633703955456,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.23583494916655862,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 507,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9118248515058879,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06919363598672357,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 480,
            "feature_preprocessor:nystroem_sampler:coef0": 0.34716595691269814,
            "feature_preprocessor:nystroem_sampler:gamma": 0.008083810996133216
        },
        "cost": 0.0,
        "time": 0.46230316162109375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 102,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.27588870699775936,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.7923148649741485,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 566,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005977973351679884,
            "feature_preprocessor:select_rates_classification:alpha": 0.46803316111238147,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.0969675473680407,
        "time": 10.409302234649658,
        "additional_info": {
            "duration": 10.393080949783325,
            "num_run": 103,
            "train_loss": 1.034571650926564,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 103,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.7763235277832409,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.49089244911249774,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 10,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 426,
            "feature_preprocessor:select_rates_classification:alpha": 0.012179747132717484,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.0843444586529751,
        "time": 3.650916814804077,
        "additional_info": {
            "duration": 3.6387341022491455,
            "num_run": 104,
            "train_loss": 1.0670796884178508,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 104,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.622400650029938,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.6566273694326836,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 444,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 650,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 95,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0019198573551621335
        },
        "cost": 1.1294392760501486,
        "time": 73.84994196891785,
        "additional_info": {
            "duration": 73.83607316017151,
            "num_run": 105,
            "train_loss": 1.0110451081153589,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 105,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.5315597501191491,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.5538408176064873,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 562,
            "feature_preprocessor:select_rates_classification:alpha": 0.45782457620335104,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12260198593139648,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 106,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.647612643098971,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.688033166884229,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 516,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 217
        },
        "cost": 0.0,
        "time": 0.4750959873199463,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 107,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.6739855898035707,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.7362863386248075,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 522,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11163730856324076,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 2889,
            "feature_preprocessor:nystroem_sampler:gamma": 5.042031453909931
        },
        "cost": 0.0,
        "time": 33.14078426361084,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 108,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.3863438462228918,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.3618514897074297,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 535,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 1373
        },
        "cost": 0.0,
        "time": 8.48563265800476,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 109,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.7127899474651143,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.6551416793778395,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 335,
            "feature_preprocessor:select_rates_classification:alpha": 0.22857071112333935,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.4711461067199707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 110,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.3433556331503138,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.7515981508871282,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 10,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 382,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006821660370586599,
            "feature_preprocessor:select_rates_classification:alpha": 0.38254839411537056,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.4553539752960205,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 111,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.7190011765898427,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.5396728161212734,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 9,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 536,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8036689005899087,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19310574139936493,
            "feature_preprocessor:select_percentile_classification:percentile": 18.405435426987314,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.14631867408752441,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 112,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.6265498581206361,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.24025190526557552,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 266,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 381
        },
        "cost": 0.0,
        "time": 0.2832300662994385,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 113,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.4794535108829243,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.6270562834138358,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 501,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 2624,
            "feature_preprocessor:nystroem_sampler:coef0": -0.5456787065149455,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 0.6400402518818714
        },
        "cost": 0.0,
        "time": 29.2988018989563,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 114,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.7719110470743119,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.4735041001951882,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 704,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020026017598900594,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1609,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 828,
            "feature_preprocessor:nystroem_sampler:gamma": 7.165073492492726e-05
        },
        "cost": 0.0,
        "time": 2.2127888202667236,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 115,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.42489225706532374,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.39258279898292464,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 12,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 262,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 78
        },
        "cost": 0.0,
        "time": 0.17196321487426758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 116,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.6759301149529248,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.7242951429947824,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 12,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 587,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016593476418199866,
            "feature_preprocessor:select_rates_classification:alpha": 0.19385061258793054,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.15831589698791504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 117,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.4600503639029162,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.5254037607551185,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 10,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 284,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000632314211311456,
            "feature_preprocessor:select_rates_classification:alpha": 0.30967590572161835,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.0931791514791735,
        "time": 3.5237488746643066,
        "additional_info": {
            "duration": 3.511626958847046,
            "num_run": 118,
            "train_loss": 1.0780838697416883,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 118,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.4442563220642048,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.2850706626467561,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 10,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 487,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 719,
            "feature_preprocessor:nystroem_sampler:coef0": -0.27138951446930126,
            "feature_preprocessor:nystroem_sampler:gamma": 0.35324864650575033
        },
        "cost": 0.0,
        "time": 2.978963851928711,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 119,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6132801352172457,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.4447293019407318,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 422,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8307898125881259,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1158122581966541,
            "feature_preprocessor:select_percentile_classification:percentile": 25.358619633625274,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.19107460975646973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 120,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.46962406698645603,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.6527139556791256,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 720,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 285,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.3379931938751184,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.2648887634277344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 121,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.5956682432165593,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.4660910661795369,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 374,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 3808
        },
        "cost": 0.0,
        "time": 51.732285022735596,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 122,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.7394531570434699,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.8142798592097433,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 305,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 2057,
            "feature_preprocessor:nystroem_sampler:coef0": 0.49664453044080337,
            "feature_preprocessor:nystroem_sampler:degree": 4,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0554826359818654
        },
        "cost": 0.0,
        "time": 359.99955105781555,
        "additional_info": {
            "error": "Timeout",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 123,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.6900944043790185,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.6159626900397983,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 345,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013078713003139103,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9108055288195034,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.022376823846871077,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 126,
            "feature_preprocessor:nystroem_sampler:coef0": 0.31379967669269315,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 5.814721006486686e-05
        },
        "cost": 0.0,
        "time": 0.23438000679016113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 124,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.3254615952455031,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.2457550227508526,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 592,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.46306123012517447,
            "feature_preprocessor:select_percentile_classification:percentile": 82.79206042287831,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 1.9947340488433838,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 125,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.7670116069743568,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.31339910312581865,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 739,
            "feature_preprocessor:select_rates_classification:alpha": 0.09632042979420499,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.14039993286132812,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 126,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.7430404675094953,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.5624890693491735,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 561,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1980214196296606,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 4319,
            "feature_preprocessor:nystroem_sampler:coef0": -0.5230278960600978,
            "feature_preprocessor:nystroem_sampler:gamma": 0.00013047300686304663
        },
        "cost": 0.0,
        "time": 65.70397901535034,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 127,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.6543669736650537,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.6030189104856624,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 719,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8434055416306919,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25398717734743287,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 1673,
            "feature_preprocessor:nystroem_sampler:coef0": -0.928985613624355,
            "feature_preprocessor:nystroem_sampler:degree": 2,
            "feature_preprocessor:nystroem_sampler:gamma": 1.4140597817648424
        },
        "cost": 0.0,
        "time": 12.309879064559937,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 128,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.4215943730121432,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.2526922288376205,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 277,
            "feature_preprocessor:select_percentile_classification:percentile": 82.04256469409323,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.1619119644165039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 129,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.4865962390027088,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.4111512697867975,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 472,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019797012183484508,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 735,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.49039268026753335,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.20688605308532715,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 130,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.30719271726609565,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.326184900309406,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 9,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 449,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001971969185428926,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1710,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 65.24061338250736,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.2793080806732178,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 131,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.7247208003386267,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.6986652439994662,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 288,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1964,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 4807,
            "feature_preprocessor:nystroem_sampler:gamma": 0.04615775886919663
        },
        "cost": 0.0,
        "time": 78.56667590141296,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 132,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.3942378023918305,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.742104221763199,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 491,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 180,
            "feature_preprocessor:nystroem_sampler:gamma": 6.395562537277702e-05
        },
        "cost": 0.0,
        "time": 0.6946520805358887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 133,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.5429007183878655,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.7092152589460472,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 270,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009190346946762263,
            "feature_preprocessor:select_rates_classification:alpha": 0.46786514702649473,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.0941711191534176,
        "time": 6.623182058334351,
        "additional_info": {
            "duration": 6.609861135482788,
            "num_run": 134,
            "train_loss": 1.0034813326020764,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 134,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.4851156474330191,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.5529894613444515,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 565,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006344053253135419,
            "feature_preprocessor:select_rates_classification:alpha": 0.38584330339362566,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 2.016472101211548,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 135,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.6526326046900952,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.564708207118661,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 377,
            "feature_preprocessor:select_rates_classification:alpha": 0.11366000898273901,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.1021509321591691,
        "time": 5.51518988609314,
        "additional_info": {
            "duration": 5.500279664993286,
            "num_run": 136,
            "train_loss": 1.0353527094046822,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 136,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.3360927192489935,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.3880910916735486,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 673,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006984639519163064,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 368,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 71.38395553934524,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.087573019628959,
        "time": 6.681311130523682,
        "additional_info": {
            "duration": 6.665305137634277,
            "num_run": 137,
            "train_loss": 1.0657412446365304,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 137,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.7481204652168105,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.621633781661468,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 12,
            "classifier:CustomGBC:min_samples_split": 10,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 314,
            "feature_preprocessor:select_percentile_classification:percentile": 20.684929201955587,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1174284858949766,
        "time": 5.611191034317017,
        "additional_info": {
            "duration": 5.598182916641235,
            "num_run": 138,
            "train_loss": 1.0749182023615236,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 138,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.358181052212204,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.8098986865253632,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 438,
            "feature_preprocessor:select_rates_classification:alpha": 0.4945945369342817,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.18075990676879883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 139,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.30663923503484136,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.691449826977628,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 9,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 342,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022409331560699523,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 315,
            "feature_preprocessor:nystroem_sampler:coef0": -0.8050725426932597,
            "feature_preprocessor:nystroem_sampler:gamma": 0.000520756138222331
        },
        "cost": 0.0,
        "time": 0.331820011138916,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 140,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.31631207111769544,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.680236099280732,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 683,
            "feature_preprocessor:select_rates_classification:alpha": 0.19408903205505323,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1502540111541748,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 141,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.7572114374208989,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.39472882671965376,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 12,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 473,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006047833260904314,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 83,
            "feature_preprocessor:nystroem_sampler:coef0": -0.9481473342963198,
            "feature_preprocessor:nystroem_sampler:degree": 2,
            "feature_preprocessor:nystroem_sampler:gamma": 2.344986823398906
        },
        "cost": 0.0,
        "time": 0.20423293113708496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 142,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.6284193332292595,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.3749057593868662,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 460,
            "feature_preprocessor:select_percentile_classification:percentile": 69.68100608503048,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.12651801109313965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 143,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.3204661798155202,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.5063043852360156,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 682,
            "feature_preprocessor:select_rates_classification:alpha": 0.2966971601984695,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.1405287291590045,
        "time": 4.8940370082855225,
        "additional_info": {
            "duration": 4.878965139389038,
            "num_run": 144,
            "train_loss": 1.1405330874135444,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 144,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.643155782414561,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.2421666074525135,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 349,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7707306494711915,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17852817214942213,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 1839,
            "feature_preprocessor:nystroem_sampler:coef0": 0.11435452424408377,
            "feature_preprocessor:nystroem_sampler:gamma": 0.06198668342464549
        },
        "cost": 0.0,
        "time": 15.013254165649414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 145,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.762792471708327,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.26054813982144337,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 8,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 266,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018670565821890497,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1416,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 43.72788043708843,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.0924564170467415,
        "time": 3.947361946105957,
        "additional_info": {
            "duration": 3.9348721504211426,
            "num_run": 146,
            "train_loss": 1.0583414597368226,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 146,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.6761176628952321,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.7133205550397553,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 13,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 253,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 814,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.08983073245803393,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.258220911026001,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 147,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.35207114533005884,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.7436375984125618,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 6,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 258,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1867,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 2490,
            "feature_preprocessor:nystroem_sampler:coef0": 0.1431729151365977,
            "feature_preprocessor:nystroem_sampler:gamma": 0.14980040146703816
        },
        "cost": 0.0,
        "time": 26.308178901672363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 148,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.2730181886283683,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.544621928731458,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 526,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8776151336702758,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.038666841531911855,
            "feature_preprocessor:select_rates_classification:alpha": 0.13055750074706116,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.19614410400390625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 149,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.6487754949174582,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.44771422118974036,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 12,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 705,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2645687641656905,
            "feature_preprocessor:select_rates_classification:alpha": 0.31817600651932576,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.43835973739624023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 150,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.3454873743357071,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.41679090677074265,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 12,
            "classifier:CustomGBC:min_samples_split": 12,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 530,
            "feature_preprocessor:select_percentile_classification:percentile": 59.02747957917112,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.16225099563598633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 151,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.40248485360460146,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.2939797229850048,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 718,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015199126392649448,
            "feature_preprocessor:select_rates_classification:alpha": 0.2656213330799173,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.1035100518464696,
        "time": 6.857594013214111,
        "additional_info": {
            "duration": 6.809087038040161,
            "num_run": 152,
            "train_loss": 1.0511105761012223,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 152,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.29324327271813627,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.8235856576683075,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 14,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 607,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013441820291304016,
            "feature_preprocessor:select_rates_classification:alpha": 0.4641137553954962,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.17015695571899414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 153,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.6814425141137478,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.7085898508592677,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 320,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 50,
            "feature_preprocessor:nystroem_sampler:coef0": -0.8800406177038347,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0023398388800929875
        },
        "cost": 1.1327336599760403,
        "time": 67.42657470703125,
        "additional_info": {
            "duration": 67.41436791419983,
            "num_run": 154,
            "train_loss": 1.0000578084534693,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 154,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.42877246361963073,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.2930458030268127,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 345,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1885,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 144
        },
        "cost": 1.1157537211211126,
        "time": 10.487552642822266,
        "additional_info": {
            "duration": 10.475425243377686,
            "num_run": 155,
            "train_loss": 1.0630907371996867,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 155,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.3866466122580902,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.3733226707027804,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 13,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 606,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010332090260618632,
            "feature_preprocessor:select_percentile_classification:percentile": 10.025573476763565,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 0.0,
        "time": 0.18183588981628418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 156,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.4158292910066717,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.34181341540256627,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 6,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 673,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00101816974788127,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 1929
        },
        "cost": 0.0,
        "time": 15.436346292495728,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 157,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.7269094965874114,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.27760429636965794,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 12,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 340,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0027184372606465575,
            "feature_preprocessor:select_rates_classification:alpha": 0.13789624444099677,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 0.0,
        "time": 2.003246784210205,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 158,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.4159083465001141,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 9,
            "classifier:CustomGBC:max_features": 0.6443766918728183,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 12,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 485,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 52,
            "feature_preprocessor:nystroem_sampler:gamma": 0.02933410823142711
        },
        "cost": 1.132557178016583,
        "time": 89.58061480522156,
        "additional_info": {
            "duration": 89.56615400314331,
            "num_run": 159,
            "train_loss": 1.0005747311874091,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 159,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.636502451281703,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 8,
            "classifier:CustomGBC:max_features": 0.7890025570020537,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 10,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 334,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1150,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 2407,
            "feature_preprocessor:nystroem_sampler:gamma": 0.006069211587532609
        },
        "cost": 0.0,
        "time": 360.0008690357208,
        "additional_info": {
            "error": "Timeout",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 160,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.6120105641328719,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.610141674255063,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 257,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002856587814769915,
            "feature_preprocessor:select_rates_classification:alpha": 0.10135124098532976,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12443995475769043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 161,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.5732394168613331,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.6615728768155679,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 12,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 672,
            "feature_preprocessor:select_percentile_classification:percentile": 77.50091944611148,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 2.0217020511627197,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 162,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.45833629550894345,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.23723752170348833,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 7,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 662,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002225421706783887,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8534281540538993,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24523576246784648,
            "feature_preprocessor:select_percentile_classification:percentile": 19.04846377437869,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.20980381965637207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 163,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.3933980141582526,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 6,
            "classifier:CustomGBC:max_features": 0.2501769908424026,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 723,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.883871026488529,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10557919274817912,
            "feature_preprocessor:select_percentile_classification:percentile": 89.6967832319522,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 0.0,
        "time": 0.2009270191192627,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 164,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.7463213228723904,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.5230266748867154,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 8,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 592,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7702121124195087,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2323309983908258,
            "feature_preprocessor:select_rates_classification:alpha": 0.47151486295113937,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.17286300659179688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 165,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.44078759268596185,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.25067119158428053,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 7,
            "classifier:CustomGBC:min_samples_split": 12,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 283,
            "feature_preprocessor:select_percentile_classification:percentile": 62.083356150062684,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.0911259767581374,
        "time": 4.825774192810059,
        "additional_info": {
            "duration": 4.814499139785767,
            "num_run": 166,
            "train_loss": 1.0711761029564857,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 166,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.3936771105235208,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.526101334833054,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 16,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 266,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001514481438848358,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 3472,
            "feature_preprocessor:nystroem_sampler:coef0": -0.7551722036528126,
            "feature_preprocessor:nystroem_sampler:gamma": 0.015844045567614155
        },
        "cost": 1.1405287291590045,
        "time": 146.12625575065613,
        "additional_info": {
            "duration": 146.10163497924805,
            "num_run": 167,
            "train_loss": 1.1405330874135444,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 167,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.26495335412918597,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 3,
            "classifier:CustomGBC:max_features": 0.5069195274101268,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 544,
            "feature_preprocessor:select_percentile_classification:percentile": 44.79018101388345,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1014030787452136,
        "time": 5.076067924499512,
        "additional_info": {
            "duration": 5.061630964279175,
            "num_run": 168,
            "train_loss": 1.0804917924748758,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 168,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.529171829865178,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.7712388876399534,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 319,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00908631057195735,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 1060,
            "feature_preprocessor:nystroem_sampler:coef0": 0.48349621136506293,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 5.1509765460512654e-05
        },
        "cost": 0.0,
        "time": 6.101117849349976,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 169,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomGBC:learning_rate": 0.27563034864490726,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 5,
            "classifier:CustomGBC:max_features": 0.33233591155073844,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 14,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 262,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1924,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 23.880820419662655,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 0.0,
        "time": 2.1298470497131348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 170,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.4125440352497315,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.7925192061641413,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 5,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 703,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 892,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 3234,
            "feature_preprocessor:nystroem_sampler:coef0": 0.22344626754977748,
            "feature_preprocessor:nystroem_sampler:degree": 2,
            "feature_preprocessor:nystroem_sampler:gamma": 0.7046601721711835
        },
        "cost": 0.0,
        "time": 360.0475277900696,
        "additional_info": {
            "error": "Timeout",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 171,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomGBC:learning_rate": 0.45903504681771845,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.6619271525494493,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 11,
            "classifier:CustomGBC:min_samples_split": 9,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 612,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005345827153138343,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9667751961607776,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.015136609984125447,
            "feature_preprocessor:select_rates_classification:alpha": 0.12163235805578985,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1659226417541504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/adult/adult_gbc_AOD_sex.py\", line 224, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
            "error": "InvalidParameterError(\"The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 172,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.42682663310932056,
            "classifier:CustomGBC:loss": "exponential",
            "classifier:CustomGBC:max_depth": 7,
            "classifier:CustomGBC:max_features": 0.5646953717113319,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 9,
            "classifier:CustomGBC:min_samples_split": 11,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 430,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1226576263621103,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1455,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 289,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0014132678202911399
        },
        "cost": 0.0,
        "time": 64.0048189163208,
        "additional_info": {
            "error": "Timeout",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 173,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomGBC",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomGBC:learning_rate": 0.3886470775056947,
            "classifier:CustomGBC:loss": "deviance",
            "classifier:CustomGBC:max_depth": 4,
            "classifier:CustomGBC:max_features": 0.48315230251979735,
            "classifier:CustomGBC:max_leaf_nodes": "None",
            "classifier:CustomGBC:min_impurity_decrease": 0.0,
            "classifier:CustomGBC:min_samples_leaf": 15,
            "classifier:CustomGBC:min_samples_split": 15,
            "classifier:CustomGBC:min_weight_fraction_leaf": 0.0,
            "classifier:CustomGBC:n_estimators": 602,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 175,
            "feature_preprocessor:nystroem_sampler:coef0": 0.9559290558928435,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 0.015312573435683988
        },
        "cost": 0.0,
        "time": 0.0,
        "additional_info": {}
    }
]